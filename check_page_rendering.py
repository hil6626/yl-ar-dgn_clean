#!/usr/bin/env python3
"""æ£€æŸ¥YL-monitoræ‰€æœ‰é¡µé¢çš„æ¸²æŸ“æƒ…å†µ"""

import urllib.request
import urllib.error
import re
from html.parser import HTMLParser


class HTMLChecker(HTMLParser):
    def __init__(self):
        super().__init__()
        self.errors = []
        self.warnings = []
        self.scripts = []
        self.links = []
        self.stylesheets = []
        self.title = None
        self.in_title = False
        
    def handle_starttag(self, tag, attrs):
        attrs_dict = dict(attrs)
        
        # æ£€æŸ¥scriptæ ‡ç­¾
        if tag == 'script':
            src = attrs_dict.get('src', '')
            self.scripts.append(src)
            if src and not src.startswith(('http://', 'https://', '/')):
                self.warnings.append(f"Scriptè·¯å¾„å¯èƒ½é”™è¯¯: {src}")
                
        # æ£€æŸ¥linkæ ‡ç­¾
        elif tag == 'link':
            rel = attrs_dict.get('rel', '')
            href = attrs_dict.get('href', '')
            if rel == 'stylesheet':
                self.stylesheets.append(href)
                if href and not href.startswith(('http://', 'https://', '/')):
                    self.warnings.append(f"CSSè·¯å¾„å¯èƒ½é”™è¯¯: {href}")
                    
        # æ£€æŸ¥title
        elif tag == 'title':
            self.in_title = True
            
    def handle_endtag(self, tag):
        if tag == 'title':
            self.in_title = False
            
    def handle_data(self, data):
        if self.in_title:
            self.title = data.strip()
            
    def check_common_issues(self, html, url):
        """æ£€æŸ¥å¸¸è§é—®é¢˜"""
        issues = []
        
        # æ£€æŸ¥æœªé—­åˆæ ‡ç­¾
        unclosed = ['<div', '<span', '<p', '<a', '<li', '<td', '<tr']
        for tag in unclosed:
            open_count = html.count(tag)
            close_count = html.count(tag.replace('<', '</'))
            if open_count != close_count:
                issues.append(f"æ ‡ç­¾ä¸å¹³è¡¡: {tag} (å¼€:{open_count}, é—­:{close_count})")
                
        # æ£€æŸ¥é‡å¤ID
        ids = re.findall(r'id=["\']([^"\']+)["\']', html)
        duplicates = set([x for x in ids if ids.count(x) > 1])
        if duplicates:
            issues.append(f"é‡å¤ID: {duplicates}")
            
        # æ£€æŸ¥console.error
        if 'console.error' in html:
            issues.append("é¡µé¢åŒ…å«console.errorè°ƒç”¨")
            
        # æ£€æŸ¥404èµ„æº
        if '404' in html and 'not found' in html.lower():
            issues.append("é¡µé¢å¯èƒ½åŒ…å«404é”™è¯¯ä¿¡æ¯")
            
        return issues


def check_page(url, name):
    """æ£€æŸ¥å•ä¸ªé¡µé¢"""
    print(f"\n{'='*60}")
    print(f"æ£€æŸ¥é¡µé¢: {name}")
    print(f"URL: {url}")
    print('='*60)
    
    try:
        req = urllib.request.Request(url)
        with urllib.request.urlopen(req, timeout=10) as response:
            html = response.read().decode('utf-8')
            
            # è§£æHTML
            checker = HTMLChecker()
            try:
                checker.feed(html)
            except Exception as e:
                print(f"âš ï¸ HTMLè§£æé”™è¯¯: {e}")
                
            # æ£€æŸ¥å¸¸è§é—®é¢˜
            issues = checker.check_common_issues(html, url)
            
            # è¾“å‡ºç»“æœ
            print(f"\nğŸ“„ é¡µé¢æ ‡é¢˜: {checker.title or 'æœªæ‰¾åˆ°'}")
            print(f"ğŸ“Š é¡µé¢å¤§å°: {len(html)} å­—èŠ‚")
            print(f"ğŸ“œ Scripts: {len(checker.scripts)} ä¸ª")
            print(f"ğŸ¨ Stylesheets: {len(checker.stylesheets)} ä¸ª")
            
            # æ£€æŸ¥èµ„æºåŠ è½½
            print(f"\nğŸ” èµ„æºæ£€æŸ¥:")
            base_url = url.rsplit('/', 1)[0] if '/' in url else url
            
            # æ£€æŸ¥CSSæ–‡ä»¶
            for css in checker.stylesheets:
                if css.startswith('http'):
                    css_url = css
                elif css.startswith('/'):
                    css_url = f"http://localhost:5500{css}"
                else:
                    css_url = f"{base_url}/{css}"
                    
                try:
                    css_req = urllib.request.Request(css_url)
                    with urllib.request.urlopen(css_req, timeout=5) as css_resp:
                        print(f"  âœ… CSS: {css} ({css_resp.status})")
                except Exception as e:
                    print(f"  âŒ CSSåŠ è½½å¤±è´¥: {css} - {e}")
                    
            # æ£€æŸ¥JSæ–‡ä»¶
            for js in checker.scripts:
                if not js:
                    continue
                if js.startswith('http'):
                    js_url = js
                elif js.startswith('/'):
                    js_url = f"http://localhost:5500{js}"
                else:
                    js_url = f"{base_url}/{js}"
                    
                try:
                    js_req = urllib.request.Request(js_url)
                    with urllib.request.urlopen(js_req, timeout=5) as js_resp:
                        print(f"  âœ… JS: {js} ({js_resp.status})")
                except Exception as e:
                    print(f"  âŒ JSåŠ è½½å¤±è´¥: {js} - {e}")
            
            # æŠ¥å‘Šé—®é¢˜
            if issues:
                print(f"\nâš ï¸ å‘ç°çš„é—®é¢˜:")
                for issue in issues:
                    print(f"  - {issue}")
            else:
                print(f"\nâœ… æœªå‘ç°æ˜æ˜¾æ¸²æŸ“é—®é¢˜")
                
            # æ£€æŸ¥ç‰¹å®šé”™è¯¯æ¨¡å¼
            error_patterns = [
                (r'error|exception|fail', "åŒ…å«é”™è¯¯å…³é”®è¯"),
                (r'undefined|NaN|null', "åŒ…å«æœªå®šä¹‰å€¼"),
                (r'class=["\'][^"\']*error', "åŒ…å«é”™è¯¯æ ·å¼ç±»"),
                (r'style=["\'][^"\']*display:\s*none', "åŒ…å«éšè—å…ƒç´ "),
            ]
            
            found_patterns = []
            for pattern, desc in error_patterns:
                if re.search(pattern, html, re.IGNORECASE):
                    found_patterns.append(desc)
                    
            if found_patterns:
                print(f"\nğŸ” å†…å®¹æ¨¡å¼æ£€æŸ¥:")
                for pattern in found_patterns:
                    print(f"  âš ï¸ {pattern}")
                    
            return {
                'name': name,
                'url': url,
                'status': response.status,
                'title': checker.title,
                'size': len(html),
                'issues': issues,
                'patterns': found_patterns
            }
            
    except urllib.error.HTTPError as e:
        print(f"âŒ HTTPé”™è¯¯: {e.code} - {e.reason}")
        return {'name': name, 'url': url, 'error': f"HTTP {e.code}"}
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return {'name': name, 'url': url, 'error': str(e)}


def main():
    base = 'http://localhost:5500'
    
    pages = [
        ('/', 'é¦–é¡µ'),
        ('/dashboard', 'ä»ªè¡¨ç›˜'),
        ('/scripts', 'è„šæœ¬ç®¡ç†'),
        ('/dag', 'DAGå·¥ä½œæµ'),
        ('/ar', 'ARç›‘æ§'),
        ('/alert-rules', 'å‘Šè­¦è§„åˆ™'),
        ('/alert-analytics', 'å‘Šè­¦åˆ†æ'),
        ('/intelligent-alert', 'æ™ºèƒ½å‘Šè­¦'),
        ('/api-doc', 'APIæ–‡æ¡£'),
        ('/alerts', 'å‘Šè­¦åˆ—è¡¨'),
    ]
    
    results = []
    
    print("="*60)
    print("YL-monitor é¡µé¢æ¸²æŸ“æ£€æŸ¥")
    print("="*60)
    
    for path, name in pages:
        url = f"{base}{path}"
        result = check_page(url, name)
        results.append(result)
        
    # æ±‡æ€»æŠ¥å‘Š
    print(f"\n{'='*60}")
    print("æ±‡æ€»æŠ¥å‘Š")
    print('='*60)
    
    success = [r for r in results if 'error' not in r]
    failed = [r for r in results if 'error' in r]
    with_issues = [r for r in success if r.get('issues') or r.get('patterns')]
    
    print(f"\nâœ… æ­£å¸¸é¡µé¢: {len(success)}/{len(results)}")
    print(f"âŒ å¤±è´¥é¡µé¢: {len(failed)}/{len(results)}")
    print(f"âš ï¸ æœ‰é—®é¢˜é¡µé¢: {len(with_issues)}/{len(results)}")
    
    if failed:
        print(f"\nâŒ å¤±è´¥é¡µé¢è¯¦æƒ…:")
        for r in failed:
            print(f"  - {r['name']}: {r['error']}")
            
    if with_issues:
        print(f"\nâš ï¸ éœ€å…³æ³¨é¡µé¢:")
        for r in with_issues:
            issues = r.get('issues', []) + r.get('patterns', [])
            print(f"  - {r['name']}: {len(issues)} ä¸ªé—®é¢˜")
            
    print(f"\n{'='*60}")
    print("æ£€æŸ¥å®Œæˆ")
    print('='*60)


if __name__ == '__main__':
    main()
