#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…·
AR ç»¼åˆå®æ—¶åˆæˆä¸ç›‘æ§ç³»ç»Ÿ

åŠŸèƒ½:
- åˆå§‹åŒ–æ—¶é—´æµ‹è¯•
- å¹¶å‘å¤„ç†æ€§èƒ½æµ‹è¯•
- èµ„æºä½¿ç”¨ç›‘æ§
- å†…å­˜æ³„æ¼æ£€æµ‹

ä½œè€…: AI å…¨æ ˆæŠ€æœ¯å‘˜
ç‰ˆæœ¬: 1.0
åˆ›å»ºæ—¥æœŸ: 2026å¹´2æœˆ9æ—¥
"""

import sys
import os
import time
import psutil
import threading
import json
from typing import Dict, List, Any
from pathlib import Path

TEST_DIR = Path(__file__).resolve().parents[1]
if str(TEST_DIR) not in sys.path:
    sys.path.insert(0, str(TEST_DIR))

from test_utils import add_project_paths

PATHS = add_project_paths()

from camera import CameraModule
from audio_module import AudioModule
from processor_manager import ProcessorManager


class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•ç±»"""

    def __init__(self):
        self.results = {}
        self.process = psutil.Process()
        self.start_time = time.time()

    def get_memory_usage(self) -> Dict[str, float]:
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        mem = self.process.memory_info()
        return {
            'rss': mem.rss / 1024 / 1024,  # MB
            'vms': mem.vms / 1024 / 1024,  # MB
            'percent': self.process.memory_percent()
        }

    def get_cpu_usage(self) -> float:
        """è·å–CPUä½¿ç”¨ç‡"""
        return self.process.cpu_percent(interval=1.0)

    def benchmark_initialization(self) -> Dict[str, Any]:
        """æµ‹è¯•æ¨¡å—åˆå§‹åŒ–æ€§èƒ½"""
        print("ğŸ”„ æµ‹è¯•æ¨¡å—åˆå§‹åŒ–æ€§èƒ½...")

        results = {}

        # æµ‹è¯• CameraModule åˆå§‹åŒ–
        start_time = time.time()
        camera = CameraModule()
        init_time = time.time() - start_time
        results['camera_init'] = {
            'time': init_time,
            'memory': self.get_memory_usage(),
            'success': True
        }

        # æµ‹è¯• AudioModule åˆå§‹åŒ–
        start_time = time.time()
        audio = AudioModule()
        init_time = time.time() - start_time
        results['audio_init'] = {
            'time': init_time,
            'memory': self.get_memory_usage(),
            'success': True
        }

        # æµ‹è¯• ProcessorManager åˆå§‹åŒ–
        start_time = time.time()
        manager = ProcessorManager()
        init_time = time.time() - start_time
        results['processor_init'] = {
            'time': init_time,
            'memory': self.get_memory_usage(),
            'success': True
        }

        return results

    def benchmark_concurrent_processing(self, duration: int = 10) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘å¤„ç†æ€§èƒ½"""
        print(f"ğŸ”„ æµ‹è¯•å¹¶å‘å¤„ç†æ€§èƒ½ ({duration}ç§’)...")

        results = {
            'duration': duration,
            'cpu_samples': [],
            'memory_samples': [],
            'frame_counts': []
        }

        # å¯åŠ¨æ‘„åƒå¤´
        camera = CameraModule()
        if not camera.start_capture():
            return {'error': 'æ— æ³•å¯åŠ¨æ‘„åƒå¤´'}

        start_time = time.time()
        frame_count = 0

        try:
            while time.time() - start_time < duration:
                # è·å–å¸§
                frame = camera.get_frame()
                if frame is not None:
                    frame_count += 1

                # è®°å½•æ€§èƒ½æ•°æ®
                results['cpu_samples'].append(self.get_cpu_usage())
                results['memory_samples'].append(self.get_memory_usage())

                time.sleep(0.1)  # 10fps é‡‡æ ·

        finally:
            camera.stop_capture()

        results['frame_counts'] = frame_count
        results['fps_actual'] = frame_count / duration

        return results

    def benchmark_resource_monitoring(self, duration: int = 30) -> Dict[str, Any]:
        """æµ‹è¯•èµ„æºç›‘æ§ç¨³å®šæ€§"""
        print(f"ğŸ”„ æµ‹è¯•èµ„æºç›‘æ§ç¨³å®šæ€§ ({duration}ç§’)...")

        results = {
            'duration': duration,
            'cpu_stats': {'min': float('inf'), 'max': 0, 'avg': 0},
            'memory_stats': {'min': float('inf'), 'max': 0, 'avg': 0},
            'samples': []
        }

        samples = []
        start_time = time.time()

        while time.time() - start_time < duration:
            cpu = self.get_cpu_usage()
            memory = self.get_memory_usage()

            samples.append({
                'time': time.time() - start_time,
                'cpu': cpu,
                'memory': memory
            })

            time.sleep(1.0)

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        cpu_values = [s['cpu'] for s in samples]
        memory_values = [s['memory']['percent'] for s in samples]

        results['cpu_stats'] = {
            'min': min(cpu_values),
            'max': max(cpu_values),
            'avg': sum(cpu_values) / len(cpu_values)
        }

        results['memory_stats'] = {
            'min': min(memory_values),
            'max': max(memory_values),
            'avg': sum(memory_values) / len(memory_values)
        }

        results['samples'] = samples

        return results

    def run_full_benchmark(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å®Œæ•´æ€§èƒ½åŸºå‡†æµ‹è¯•...")

        self.results = {
            'timestamp': time.time(),
            'tests': {}
        }

        # 1. åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•
        self.results['tests']['initialization'] = self.benchmark_initialization()

        # 2. å¹¶å‘å¤„ç†æµ‹è¯•
        self.results['tests']['concurrent'] = self.benchmark_concurrent_processing()

        # 3. èµ„æºç›‘æ§æµ‹è¯•
        self.results['tests']['resources'] = self.benchmark_resource_monitoring()

        # 4. æ€»ä½“ç»Ÿè®¡
        self.results['summary'] = self._generate_summary()

        return self.results

    def _generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ€»ç»“"""
        init_tests = self.results['tests']['initialization']
        concurrent_tests = self.results['tests']['concurrent']
        resource_tests = self.results['tests']['resources']

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€§èƒ½ç›®æ ‡
        targets = {
            'init_time_max': 5.0,  # ç§’
            'memory_max': 800.0,   # MB
            'cpu_max': 80.0,       # %
            'fps_min': 25.0        # fps
        }

        summary = {
            'targets': targets,
            'results': {},
            'passed': True,
            'details': []
        }

        # åˆå§‹åŒ–æ—¶é—´æ£€æŸ¥
        total_init_time = sum(test['time'] for test in init_tests.values())
        summary['results']['init_time'] = total_init_time
        if total_init_time > targets['init_time_max']:
            summary['passed'] = False
            summary['details'].append(f"åˆå§‹åŒ–æ—¶é—´è¿‡é•¿: {total_init_time:.2f}s > {targets['init_time_max']}s")

        # å†…å­˜ä½¿ç”¨æ£€æŸ¥
        if 'concurrent' in self.results['tests']:
            memory_usage = concurrent_tests.get('memory_samples', [])
            if memory_usage:
                avg_memory = sum(s['percent'] for s in memory_usage) / len(memory_usage)
                summary['results']['memory_avg'] = avg_memory
                if avg_memory > targets['memory_max']:
                    summary['passed'] = False
                    summary['details'].append(f"å†…å­˜ä½¿ç”¨è¿‡é«˜: {avg_memory:.1f}% > {targets['memory_max']}%")

        # CPUä½¿ç”¨æ£€æŸ¥
        if 'resources' in self.results['tests']:
            cpu_avg = resource_tests['cpu_stats']['avg']
            summary['results']['cpu_avg'] = cpu_avg
            if cpu_avg > targets['cpu_max']:
                summary['passed'] = False
                summary['details'].append(f"CPUä½¿ç”¨è¿‡é«˜: {cpu_avg:.1f}% > {targets['cpu_max']}%")

        # FPSæ£€æŸ¥
        if 'concurrent' in self.results['tests']:
            fps_actual = concurrent_tests.get('fps_actual', 0)
            summary['results']['fps_actual'] = fps_actual
            if fps_actual < targets['fps_min']:
                summary['passed'] = False
                summary['details'].append(f"FPSè¿‡ä½: {fps_actual:.1f} < {targets['fps_min']}")

        return summary

    def save_results(self, filename: str = None) -> str:
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        if filename is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"benchmark_results_{timestamp}.json"

        filepath = Path(__file__).parent / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
        return str(filepath)

    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        if not self.results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return

        summary = self.results.get('summary', {})
        print("\n" + "="*50)
        print("ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœæ€»ç»“")
        print("="*50)

        if summary.get('passed', False):
            print("âœ… æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡å‡è¾¾åˆ°è¦æ±‚ï¼")
        else:
            print("âŒ éƒ¨åˆ†æ€§èƒ½æŒ‡æ ‡æœªè¾¾åˆ°è¦æ±‚ï¼š")
            for detail in summary.get('details', []):
                print(f"  - {detail}")

        print("\nğŸ“ˆ è¯¦ç»†æŒ‡æ ‡:"        targets = summary.get('targets', {})
        results = summary.get('results', {})

        print(".2f"        print(".1f"        print(".1f"        print(".1f"
        print("\nğŸ” æµ‹è¯•è¯¦æƒ…:"        tests = self.results.get('tests', {})

        if 'initialization' in tests:
            init = tests['initialization']
            print(".2f"            print(".2f"            print(".2f"
        if 'concurrent' in tests:
            concurrent = tests['concurrent']
            print(".1f"            print(f"  - å¤„ç†å¸§æ•°: {concurrent.get('frame_counts', 0)}")

        if 'resources' in tests:
            resources = tests['resources']
            cpu_stats = resources.get('cpu_stats', {})
            mem_stats = resources.get('memory_stats', {})
            print(".1f"            print(".1f"            print(".1f"            print(".1f"
        print("="*50)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='ARç³»ç»Ÿæ€§èƒ½åŸºå‡†æµ‹è¯•')
    parser.add_argument('--full', action='store_true', help='è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶')
    parser.add_argument('--init-only', action='store_true', help='ä»…æµ‹è¯•åˆå§‹åŒ–æ€§èƒ½')
    parser.add_argument('--concurrent', type=int, default=10, help='å¹¶å‘æµ‹è¯•æ—¶é•¿(ç§’)')
    parser.add_argument('--resources', type=int, default=30, help='èµ„æºç›‘æ§æ—¶é•¿(ç§’)')
    parser.add_argument('--output', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')

    args = parser.parse_args()

    benchmark = PerformanceBenchmark()

    try:
        if args.full:
            results = benchmark.run_full_benchmark()
        elif args.init_only:
            results = {'tests': {'initialization': benchmark.benchmark_initialization()}}
        else:
            results = {
                'tests': {
                    'concurrent': benchmark.benchmark_concurrent_processing(args.concurrent),
                    'resources': benchmark.benchmark_resource_monitoring(args.resources)
                }
            }

        if args.json:
            print(json.dumps(results, indent=2, ensure_ascii=False))
        else:
            benchmark.print_summary()

        if args.output:
            benchmark.save_results(args.output)

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == '__main__':
    sys.exit(main())
