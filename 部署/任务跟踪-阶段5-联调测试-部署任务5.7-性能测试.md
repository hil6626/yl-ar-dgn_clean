# Phase 5 - Task 5.7: Performance Testing - Detailed Deployment Document

**Task ID:** 5.7  
**Task Name:** Performance Testing  
**Priority:** P1 (High)  
**Estimated Hours:** 3 hours  
**Status:** Pending  
**Prerequisites:** Task 5.6 completed

---

## I. Task Objectives

Test system performance under various loads to ensure it meets requirements.

## II. Performance Requirements

### 2.1 Target Metrics

| Metric | Target | Maximum |
|--------|--------|---------|
| API response time | < 200ms | < 500ms |
| Video processing FPS | > 25 | > 15 |
| Memory usage | < 2GB | < 4GB |
| CPU usage | < 50% | < 80% |
| Concurrent users | 10 | 20 |

## III. Deployment Content

### 3.1 Performance Test Script

#### File: test/performance/test_performance.py

```python
#!/usr/bin/env python3
"""
Performance Tests
"""

import unittest
import time
import statistics
import requests
import psutil
import concurrent.futures
from pathlib import Path


class TestAPIPerformance(unittest.TestCase):
    """
    Test API performance
    """

    BASE_URL = "http://localhost:5500"

    def test_health_check_response_time(self):
        """Test health check response time"""
        times = []

        for _ in range(10):
            start = time.time()
            try:
                response = requests.get(
                    f"{self.BASE_URL}/api/health",
                    timeout=5
                )
                elapsed = time.time() - start
                times.append(elapsed)
            except requests.RequestException:
                self.skipTest("API not accessible")

        if times:
            avg_time = statistics.mean(times)
            max_time = max(times)

            print(f"Health check times: avg={avg_time:.3f}s, max={max_time:.3f}s")

            self.assertLess(avg_time, 0.5)  # Average < 500ms
            self.assertLess(max_time, 1.0)  # Max < 1s

    def test_concurrent_api_calls(self):
        """Test concurrent API calls"""
        def make_request():
            try:
                start = time.time()
                response = requests.get(
                    f"{self.BASE_URL}/api/health",
                    timeout=5
                )
                elapsed = time.time() - start
                return response.status_code == 200, elapsed
            except:
                return False, 0

        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(make_request) for _ in range(20)]
            results = [f.result() for f in concurrent.futures.as_completed(futures)]

        successful = sum(1 for success, _ in results if success)
        times = [t for _, t in results if t > 0]

        print(f"Concurrent requests: {successful}/20 successful")

        self.assertGreaterEqual(successful, 18)  # 90% success rate

        if times:
            avg_time = statistics.mean(times)
            print(f"Average response time: {avg_time:.3f}s")
            self.assertLess(avg_time, 1.0)

    def test_api_throughput(self):
        """Test API throughput"""
        duration = 10  # seconds
        count = 0
        start = time.time()

        while time.time() - start < duration:
            try:
                response = requests.get(
                    f"{self.BASE_URL}/api/health",
                    timeout=2
                )
                if response.status_code == 200:
                    count += 1
            except:
                pass

        throughput = count / duration
        print(f"API throughput: {throughput:.1f} requests/second")

        self.assertGreater(throughput, 5)  # At least 5 req/s


class TestResourceUsage(unittest.TestCase):
    """
    Test resource usage
    """

    def test_memory_usage(self):
        """Test memory usage"""
        process = psutil.Process()
        mem_info = process.memory_info()

        print(f"Memory usage: {mem_info.rss / 1024 / 1024:.1f} MB")

        # Memory should be reasonable
        self.assertLess(mem_info.rss, 4 * 1024 * 1024 * 1024)  # < 4GB

    def test_cpu_usage(self):
        """Test CPU usage"""
        cpu_percent = psutil.cpu_percent(interval=1)

        print(f"CPU usage: {cpu_percent}%")

        # CPU should not be maxed out during tests
        self.assertLess(cpu_percent, 90)

    def test_disk_io(self):
        """Test disk I/O"""
        disk_io = psutil.disk_io_counters()

        if disk_io:
            print(f"Disk read: {disk_io.read_bytes / 1024 / 1024:.1f} MB")
            print(f"Disk write: {disk_io.write_bytes / 1024 / 1024:.1f} MB")


class TestLoadPerformance(unittest.TestCase):
    """
    Test performance under load
    """

    def test_sustained_load(self):
        """Test sustained load over time"""
        duration = 30  # seconds
        interval = 1  # second

        times = []
        errors = 0

        start = time.time()
        while time.time() - start < duration:
            try:
                t0 = time.time()
                response = requests.get(
                    "http://localhost:5500/api/health",
                    timeout=5
                )
                t1 = time.time()

                if response.status_code == 200:
                    times.append(t1 - t0)
                else:
                    errors += 1
            except Exception as e:
                errors += 1

            time.sleep(interval)

        if times:
            avg_time = statistics.mean(times)
            print(f"Sustained load: avg={avg_time:.3f}s, errors={errors}")

            self.assertLess(avg_time, 1.0)
            self.assertEqual(errors, 0)


def run_performance_tests():
    """Run all performance tests"""
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()

    suite.addTests(loader.loadTestsFromTestCase(TestAPIPerformance))
    suite.addTests(loader.loadTestsFromTestCase(TestResourceUsage))
    suite.addTests(loader.loadTestsFromTestCase(TestLoadPerformance))

    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    return result.wasSuccessful()


if __name__ == '__main__':
    success = run_performance_tests()
    exit(0 if success else 1)
```

### 3.2 Performance Test Runner

#### File: test/performance/run_performance_tests.sh

```bash
#!/bin/bash
# Run Performance Tests

set -e

PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
LOG_FILE="$PROJECT_ROOT/logs/performance_tests_$(date +%Y%m%d_%H%M%S).log"

mkdir -p "$(dirname "$LOG_FILE")"

echo "========================================"
echo "Performance Tests"
echo "Started: $(date)"
echo "========================================"

# Check prerequisites
echo ""
echo "Checking prerequisites..."

if ! python3 -c "import psutil" 2>/dev/null; then
    echo "Installing psutil..."
    pip3 install psutil
fi

# Check if services are running
echo ""
echo "Checking service status..."

if ! curl -s http://localhost:5500/api/health > /dev/null 2>&1; then
    echo "  ⚠ YL-monitor is not running - some tests will be skipped"
fi

# Run performance tests
echo ""
echo "Running performance tests..."

cd "$PROJECT_ROOT"
if python3 test/performance/test_performance.py 2>&1 | tee -a "$LOG_FILE"; then
    echo ""
    echo "✓ Performance tests completed"
    TEST_RESULT=0
else
    echo ""
    echo "✗ Some performance tests failed"
    TEST_RESULT=1
fi

# Generate summary
echo ""
echo "========================================"
echo "Performance Test Summary"
echo "========================================"
echo "Log file: $LOG_FILE"

# Extract metrics from log
if [ -f "$LOG_FILE" ]; then
    echo ""
    echo "Key Metrics:"
    grep -E "(response time|throughput|Memory|CPU)" "$LOG_FILE" | tail -n 10 || true
fi

exit $TEST_RESULT
```

## IV. Deployment Steps

```bash
# 1. Create performance test directory
mkdir -p test/performance

# 2. Create performance test
# Edit test/performance/test_performance.py

# 3. Create test runner
# Edit test/performance/run_performance_tests.sh

# 4. Make executable
chmod +x test/performance/run_performance_tests.sh

# 5. Install dependency
pip3 install psutil

# 6. Run tests
./test/performance/run_performance_tests.sh
```

## V. Verification Checklist

- [ ] API response time < 500ms
- [ ] Concurrent requests handled
- [ ] Throughput > 5 req/s
- [ ] Memory usage < 4GB
- [ ] CPU usage < 90%
- [ ] Sustained load test passes

## VI. Next Step

After completing this task, proceed to **Task 5.8: Test Report Generation**

View document: `部署/任务跟踪-阶段5-联调测试-部署任务5.8-测试报告生成.md`
