# YL-AR-DGN é¡¹ç›®éƒ¨ç½²å®æ–½æŒ‡å—

**ç‰ˆæœ¬**: 1.0.0  
**æ›´æ–°æ—¥æœŸ**: 2026-02-16  
**ç±»å‹**: å®æ“æŒ‡å—

---

## ä¸€ã€å½“å‰å¯ç«‹å³æ‰§è¡Œçš„ä¼˜åŒ–é¡¹

åŸºäºå½“å‰é¡¹ç›®çŠ¶æ€ï¼Œä»¥ä¸‹ä¼˜åŒ–å¯ç«‹å³å®æ–½ï¼Œæ— éœ€ç­‰å¾…å…¶ä»–æ¨¡å—å®Œæˆã€‚

---

## äºŒã€ç«‹å³æ‰§è¡Œæ¸…å•ï¼ˆä»Šæ—¥å¯å®Œæˆï¼‰

### âœ… ä»»åŠ¡1: ä¿®å¤ç›‘æ§å™¨APIç«¯ç‚¹ï¼ˆ30åˆ†é’Ÿï¼‰

**é—®é¢˜**: ç›‘æ§å™¨å·²å®ç°ä½†æ— æ³•é€šè¿‡HTTPè®¿é—®

**è§£å†³æ­¥éª¤**:

1. **ä¿®æ”¹ `YL-monitor/app/main.py`**

```python
# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥
from app.api.v1.monitor import (
    infrastructure,
    system_resources,
    application,
    business,
    user_experience
)

# åœ¨åˆ›å»ºFastAPIåº”ç”¨åï¼Œæ·»åŠ è·¯ç”±æ³¨å†Œï¼ˆçº¦ç¬¬30è¡Œï¼‰
app.include_router(infrastructure.router, prefix="/api/v1/monitor")
app.include_router(system_resources.router, prefix="/api/v1/monitor")
app.include_router(application.router, prefix="/api/v1/monitor")
app.include_router(business.router, prefix="/api/v1/monitor")
app.include_router(user_experience.router, prefix="/api/v1/monitor")

# æ·»åŠ ç»Ÿä¸€ç›‘æ§ç«¯ç‚¹
@app.get("/api/v1/monitor/overview")
async def monitoring_overview():
    """è·å–äº”å±‚ç›‘æ§æ¦‚è§ˆ"""
    return {
        "layers": {
            "L1_infrastructure": {"status": "active", "endpoint": "/api/v1/monitor/infrastructure"},
            "L2_system_resources": {"status": "active", "endpoint": "/api/v1/monitor/system-resources"},
            "L3_application": {"status": "active", "endpoint": "/api/v1/monitor/application"},
            "L4_business": {"status": "active", "endpoint": "/api/v1/monitor/business"},
            "L5_user_experience": {"status": "active", "endpoint": "/api/v1/monitor/user-experience"}
        },
        "timestamp": datetime.now().isoformat()
    }
```

2. **éªŒè¯ä¿®å¤**

```bash
# å¯åŠ¨YL-monitor
cd /home/vboxuser/æ¡Œé¢/é¡¹ç›®éƒ¨ç½²/é¡¹ç›®1/yl-ar-dgn_clean/YL-monitor
python3 start_server.py &

# æµ‹è¯•ç«¯ç‚¹
curl http://0.0.0.0:5500/api/v1/monitor/overview
curl http://0.0.0.0:5500/api/v1/monitor/infrastructure
curl http://0.0.0.0:5500/api/v1/monitor/system-resources
curl http://0.0.0.0:5500/api/v1/monitor/application
curl http://0.0.0.0:5500/api/v1/monitor/business
curl http://0.0.0.0:5500/api/v1/monitor/user-experience
```

**é¢„æœŸç»“æœ**: æ‰€æœ‰ç«¯ç‚¹è¿”å›200å’ŒJSONæ•°æ®

---

### âœ… ä»»åŠ¡2: åˆ›å»ºå¿«é€Ÿå¯åŠ¨è„šæœ¬ï¼ˆ20åˆ†é’Ÿï¼‰

**åˆ›å»º `start-all.sh`**:

```bash
#!/bin/bash
# å¿«é€Ÿå¯åŠ¨æ‰€æœ‰æœåŠ¡

PROJECT_ROOT="/home/vboxuser/æ¡Œé¢/é¡¹ç›®éƒ¨ç½²/é¡¹ç›®1/yl-ar-dgn_clean"
LOG_DIR="${PROJECT_ROOT}/logs"
mkdir -p "${LOG_DIR}"

echo "ğŸš€ å¯åŠ¨ YL-AR-DGN é¡¹ç›®..."

# å¯åŠ¨AR-backend
echo "ğŸ“¡ å¯åŠ¨ AR-backend (ç«¯å£: 5501)..."
cd "${PROJECT_ROOT}/AR-backend"
nohup python3 monitor_server.py > "${LOG_DIR}/ar-backend.log" 2>&1 &
sleep 2

# å¯åŠ¨User GUI
echo "ğŸ–¥ï¸  å¯åŠ¨ User GUI (ç«¯å£: 5502)..."
cd "${PROJECT_ROOT}/user"
nohup python3 main.py > "${LOG_DIR}/user-gui.log" 2>&1 &
sleep 2

# å¯åŠ¨YL-monitor
echo "ğŸ“Š å¯åŠ¨ YL-monitor (ç«¯å£: 5500)..."
cd "${PROJECT_ROOT}/YL-monitor"
nohup python3 start_server.py > "${LOG_DIR}/yl-monitor.log" 2>&1 &
sleep 2

echo ""
echo "âœ… æ‰€æœ‰æœåŠ¡å·²å¯åŠ¨"
echo ""
echo "æœåŠ¡çŠ¶æ€:"
echo "  YL-monitor: http://0.0.0.0:5500"
echo "  AR-backend: http://0.0.0.0:5501/health"
echo "  User GUI: http://0.0.0.0:5502/status"
echo ""
echo "æŸ¥çœ‹æ—¥å¿—: tail -f ${LOG_DIR}/*.log"
echo "åœæ­¢æœåŠ¡: ./stop-all.sh"
```

**åˆ›å»º `stop-all.sh`**:

```bash
#!/bin/bash
# åœæ­¢æ‰€æœ‰æœåŠ¡

echo "ğŸ›‘ åœæ­¢ YL-AR-DGN é¡¹ç›®..."

# åœæ­¢YL-monitor
pkill -f "YL-monitor/start_server.py" || true

# åœæ­¢AR-backend
pkill -f "AR-backend/monitor_server.py" || true

# åœæ­¢User GUI
pkill -f "user/main.py" || true

sleep 2

echo "âœ… æ‰€æœ‰æœåŠ¡å·²åœæ­¢"
```

**åˆ›å»º `check-status.sh`**:

```bash
#!/bin/bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€

echo "ğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
echo ""

services=(
    "5500:YL-monitor"
    "5501:AR-backend"
    "5502:User-GUI"
)

for service in "${services[@]}"; do
    IFS=':' read -r port name <<< "$service"
    
    if lsof -Pi :${port} -sTCP:LISTEN -t >/dev/null 2>&1; then
        pid=$(lsof -Pi :${port} -sTCP:LISTEN -t 2>/dev/null)
        echo "âœ… ${name}: è¿è¡Œä¸­ (PID: ${pid}, ç«¯å£: ${port})"
    else
        echo "âŒ ${name}: æœªè¿è¡Œ (ç«¯å£: ${port})"
    fi
done
```

**è®¾ç½®æƒé™**:

```bash
chmod +x start-all.sh stop-all.sh check-status.sh
```

---

### âœ… ä»»åŠ¡3: åˆ›å»ºç»Ÿä¸€é…ç½®ï¼ˆ20åˆ†é’Ÿï¼‰

**åˆ›å»º `config/services.yaml`**:

```yaml
# YL-AR-DGN æœåŠ¡é…ç½®
version: "1.0.0"

services:
  yl-monitor:
    name: "YL-Monitor"
    description: "ç»Ÿä¸€ç›‘æ§å¹³å°"
    port: 5500
    host: "0.0.0.0"
    start_command: "python3 start_server.py"
    workdir: "YL-monitor"
    health_endpoint: "/api/health"
    enabled: true
    
  ar-backend:
    name: "AR-Backend"
    description: "ARå®æ—¶å¤„ç†åç«¯"
    port: 5501
    host: "0.0.0.0"
    start_command: "python3 monitor_server.py"
    workdir: "AR-backend"
    health_endpoint: "/health"
    enabled: true
    
  user-gui:
    name: "User-GUI"
    description: "ç”¨æˆ·æ“ä½œç•Œé¢"
    port: 5502
    host: "0.0.0.0"
    start_command: "python3 main.py"
    workdir: "user"
    health_endpoint: "/status"
    enabled: true

monitoring:
  # ç›‘æ§é‡‡é›†é…ç½®
  collection_interval: 5  # ç§’
  retention_days: 30
  
  # å‘Šè­¦é˜ˆå€¼
  thresholds:
    cpu_usage: 80
    memory_usage: 85
    disk_usage: 90
    api_response_time: 1000  # ms
    fps_drop: 10

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  directory: "logs"
  max_size: "10MB"
  backup_count: 5

paths:
  project_root: "."
  logs: "logs"
  data: "data"
  config: "config"
```

---

### âœ… ä»»åŠ¡4: åˆ›å»ºç›‘æ§éªŒè¯å·¥å…·ï¼ˆ15åˆ†é’Ÿï¼‰

**åˆ›å»º `scripts/verify-monitoring.sh`**:

```bash
#!/bin/bash
# ç›‘æ§éªŒè¯å·¥å…·

YL_MONITOR="http://0.0.0.0:5500"
AR_BACKEND="http://0.0.0.0:5501"
USER_GUI="http://0.0.0.0:5502"

echo "ğŸ” éªŒè¯ç›‘æ§ç³»ç»Ÿ..."
echo ""

# é¢œè‰²å®šä¹‰
GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

check_endpoint() {
    local name=$1
    local url=$2
    local expected_code=${3:-200}
    
    response=$(curl -s -o /dev/null -w "%{http_code}" "${url}" 2>/dev/null)
    
    if [ "$response" == "$expected_code" ]; then
        echo -e "${GREEN}âœ…${NC} ${name}: OK (${response})"
        return 0
    else
        echo -e "${RED}âŒ${NC} ${name}: å¤±è´¥ (HTTP ${response})"
        return 1
    fi
}

echo "1. åŸºç¡€æœåŠ¡æ£€æŸ¥"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
check_endpoint "YL-monitor Health" "${YL_MONITOR}/api/health"
check_endpoint "AR-backend Health" "${AR_BACKEND}/health"
check_endpoint "User GUI Status" "${USER_GUI}/status"

echo ""
echo "2. äº”å±‚ç›‘æ§æ£€æŸ¥"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
check_endpoint "L1 åŸºç¡€è®¾æ–½" "${YL_MONITOR}/api/v1/monitor/infrastructure"
check_endpoint "L2 ç³»ç»Ÿèµ„æº" "${YL_MONITOR}/api/v1/monitor/system-resources"
check_endpoint "L3 åº”ç”¨æœåŠ¡" "${YL_MONITOR}/api/v1/monitor/application"
check_endpoint "L4 ä¸šåŠ¡åŠŸèƒ½" "${YL_MONITOR}/api/v1/monitor/business"
check_endpoint "L5 ç”¨æˆ·ä½“éªŒ" "${YL_MONITOR}/api/v1/monitor/user-experience"

echo ""
echo "3. ç›‘æ§æ¦‚è§ˆ"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
curl -s "${YL_MONITOR}/api/v1/monitor/overview" | python3 -m json.tool 2>/dev/null || echo "æ— æ³•è·å–æ¦‚è§ˆ"

echo ""
echo "âœ… éªŒè¯å®Œæˆ"
```

---

## ä¸‰ã€æœ¬å‘¨å†…å®Œæˆæ¸…å•

### ğŸŸ¡ ä»»åŠ¡5: æ•°æ®æŒä¹…åŒ–ï¼ˆ2-3å°æ—¶ï¼‰

**åˆ›å»º `YL-monitor/app/core/database.py`**:

```python
"""
ç›‘æ§æ•°æ®æŒä¹…åŒ–
æ”¯æŒSQLiteå’ŒPostgreSQL
"""

import sqlite3
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import threading


class MetricsDatabase:
    """ç›‘æ§æŒ‡æ ‡æ•°æ®åº“"""
    
    def __init__(self, db_path: str = "data/monitoring.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._local = threading.local()
        self._init_db()
    
    def _get_connection(self) -> sqlite3.Connection:
        """è·å–çº¿ç¨‹æœ¬åœ°è¿æ¥"""
        if not hasattr(self._local, 'connection'):
            self._local.connection = sqlite3.connect(
                str(self.db_path),
                check_same_thread=False
            )
            self._local.connection.row_factory = sqlite3.Row
        return self._local.connection
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        # ç›‘æ§æŒ‡æ ‡è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                layer TEXT NOT NULL,
                metric_type TEXT NOT NULL,
                metric_name TEXT NOT NULL,
                value REAL,
                unit TEXT,
                service_name TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT
            )
        """)
        
        # å‘Šè­¦è®°å½•è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS alerts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                alert_type TEXT NOT NULL,
                severity TEXT NOT NULL,
                message TEXT,
                status TEXT DEFAULT 'active',
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                resolved_at DATETIME
            )
        """)
        
        # æœåŠ¡çŠ¶æ€è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS service_status (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                service_name TEXT NOT NULL,
                status TEXT,
                health_score REAL,
                last_check DATETIME,
                details TEXT
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_metrics_time ON metrics(timestamp)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_metrics_layer ON metrics(layer)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_alerts_status ON alerts(status)")
        
        conn.commit()
    
    def save_metric(self, layer: str, metric_type: str, metric_name: str,
                   value: float, unit: str = None, service_name: str = None,
                   metadata: Dict = None):
        """ä¿å­˜ç›‘æ§æŒ‡æ ‡"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO metrics (layer, metric_type, metric_name, value, unit, service_name, metadata)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            layer, metric_type, metric_name, value, unit, service_name,
            json.dumps(metadata) if metadata else None
        ))
        
        conn.commit()
    
    def get_metrics(self, layer: str = None, metric_type: str = None,
                  start_time: datetime = None, end_time: datetime = None,
                  limit: int = 1000) -> List[Dict]:
        """æŸ¥è¯¢ç›‘æ§æŒ‡æ ‡"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        query = "SELECT * FROM metrics WHERE 1=1"
        params = []
        
        if layer:
            query += " AND layer = ?"
            params.append(layer)
        
        if metric_type:
            query += " AND metric_type = ?"
            params.append(metric_type)
        
        if start_time:
            query += " AND timestamp >= ?"
            params.append(start_time.isoformat())
        
        if end_time:
            query += " AND timestamp <= ?"
            params.append(end_time.isoformat())
        
        query += " ORDER BY timestamp DESC LIMIT ?"
        params.append(limit)
        
        cursor.execute(query, params)
        
        return [dict(row) for row in cursor.fetchall()]
    
    def get_latest_metrics(self, layer: str, metric_type: str = None) -> List[Dict]:
        """è·å–æœ€æ–°æŒ‡æ ‡"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        query = """
            SELECT m.* FROM metrics m
            INNER JOIN (
                SELECT metric_name, MAX(timestamp) as max_time
                FROM metrics
                WHERE layer = ?
                GROUP BY metric_name
            ) latest ON m.metric_name = latest.metric_name AND m.timestamp = latest.max_time
            WHERE m.layer = ?
        """
        params = [layer, layer]
        
        if metric_type:
            query += " AND m.metric_type = ?"
            params.append(metric_type)
        
        cursor.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]
    
    def cleanup_old_data(self, retention_days: int = 30):
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        cutoff = datetime.now() - timedelta(days=retention_days)
        
        cursor.execute("DELETE FROM metrics WHERE timestamp < ?", (cutoff.isoformat(),))
        cursor.execute("DELETE FROM alerts WHERE status = 'resolved' AND resolved_at < ?", (cutoff.isoformat(),))
        
        deleted = cursor.rowcount
        conn.commit()
        
        return deleted


# å…¨å±€æ•°æ®åº“å®ä¾‹
metrics_db = MetricsDatabase()
```

---

### ğŸŸ¡ ä»»åŠ¡6: å‘Šè­¦é€šçŸ¥ç³»ç»Ÿï¼ˆ2-3å°æ—¶ï¼‰

**åˆ›å»º `YL-monitor/app/core/alert_manager.py`**:

```python
"""
å‘Šè­¦ç®¡ç†å™¨
æ”¯æŒå¤šæ¸ é“é€šçŸ¥
"""

import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Callable
from enum import Enum
import requests

logger = logging.getLogger(__name__)


class AlertSeverity(Enum):
    """å‘Šè­¦çº§åˆ«"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"


class AlertChannel:
    """å‘Šè­¦æ¸ é“åŸºç±»"""
    
    def send(self, alert: Dict[str, Any]) -> bool:
        raise NotImplementedError


class WebhookChannel(AlertChannel):
    """Webhooké€šçŸ¥"""
    
    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url
    
    def send(self, alert: Dict[str, Any]) -> bool:
        try:
            payload = {
                "timestamp": datetime.now().isoformat(),
                "severity": alert.get("severity"),
                "title": alert.get("title"),
                "message": alert.get("message"),
                "service": alert.get("service"),
                "metric": alert.get("metric"),
                "value": alert.get("value"),
                "threshold": alert.get("threshold")
            }
            
            response = requests.post(
                self.webhook_url,
                json=payload,
                timeout=10
            )
            
            return response.status_code == 200
            
        except Exception as e:
            logger.error(f"Webhookå‘é€å¤±è´¥: {e}")
            return False


class EmailChannel(AlertChannel):
    """é‚®ä»¶é€šçŸ¥ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    
    def __init__(self, smtp_host: str, smtp_port: int, 
                 username: str, password: str, recipients: List[str]):
        self.smtp_host = smtp_host
        self.smtp_port = smtp_port
        self.username = username
        self.password = password
        self.recipients = recipients
    
    def send(self, alert: Dict[str, Any]) -> bool:
        try:
            import smtplib
            from email.mime.text import MIMEText
            
            msg = MIMEText(alert.get("message", ""))
            msg["Subject"] = f"[{alert.get('severity', 'INFO').upper()}] {alert.get('title', 'Alert')}"
            msg["From"] = self.username
            msg["To"] = ", ".join(self.recipients)
            
            with smtplib.SMTP(self.smtp_host, self.smtp_port) as server:
                server.starttls()
                server.login(self.username, self.password)
                server.send_message(msg)
            
            return True
            
        except Exception as e:
            logger.error(f"é‚®ä»¶å‘é€å¤±è´¥: {e}")
            return False


class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self):
        self.channels: Dict[str, AlertChannel] = {}
        self.rules: List[Dict] = []
        self.alert_history: List[Dict] = []
        self._alert_cooldown: Dict[str, datetime] = {}
    
    def add_channel(self, name: str, channel: AlertChannel):
        """æ·»åŠ å‘Šè­¦æ¸ é“"""
        self.channels[name] = channel
        logger.info(f"å‘Šè­¦æ¸ é“å·²æ·»åŠ : {name}")
    
    def add_rule(self, name: str, condition: Callable, 
                 severity: AlertSeverity, channels: List[str],
                 cooldown_minutes: int = 5):
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        self.rules.append({
            "name": name,
            "condition": condition,
            "severity": severity,
            "channels": channels,
            "cooldown_minutes": cooldown_minutes
        })
        logger.info(f"å‘Šè­¦è§„åˆ™å·²æ·»åŠ : {name}")
    
    def check_alerts(self, metrics: Dict[str, Any]):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        for rule in self.rules:
            try:
                if rule["condition"](metrics):
                    self._trigger_alert(rule, metrics)
            except Exception as e:
                logger.error(f"å‘Šè­¦æ£€æŸ¥å¤±è´¥ {rule['name']}: {e}")
    
    def _trigger_alert(self, rule: Dict, metrics: Dict):
        """è§¦å‘å‘Šè­¦"""
        # æ£€æŸ¥å†·å´æ—¶é—´
        last_alert = self._alert_cooldown.get(rule["name"])
        if last_alert:
            elapsed = (datetime.now() - last_alert).total_seconds() / 60
            if elapsed < rule["cooldown_minutes"]:
                return  # å†·å´ä¸­
        
        # åˆ›å»ºå‘Šè­¦
        alert = {
            "timestamp": datetime.now().isoformat(),
            "rule": rule["name"],
            "severity": rule["severity"].value,
            "title": f"{rule['name']} å‘Šè­¦",
            "message": f"æŒ‡æ ‡å¼‚å¸¸: {metrics}",
            "service": metrics.get("service"),
            "metric": metrics.get("metric"),
            "value": metrics.get("value"),
            "threshold": metrics.get("threshold")
        }
        
        # å‘é€é€šçŸ¥
        sent = []
        for channel_name in rule["channels"]:
            channel = self.channels.get(channel_name)
            if channel:
                if channel.send(alert):
                    sent.append(channel_name)
        
        # è®°å½•å‘Šè­¦
        alert["sent_to"] = sent
        self.alert_history.append(alert)
        self._alert_cooldown[rule["name"]] = datetime.now()
        
        logger.warning(f"å‘Šè­¦è§¦å‘: {rule['name']} -> {sent}")


# å…¨å±€å‘Šè­¦ç®¡ç†å™¨
alert_manager = AlertManager()
```

---

## å››ã€å®æ–½æ£€æŸ¥æ¸…å•

### ä»Šæ—¥å®Œæˆï¼ˆå¿…åšï¼‰

- [ ] ä»»åŠ¡1: ä¿®å¤ç›‘æ§å™¨APIç«¯ç‚¹
- [ ] ä»»åŠ¡2: åˆ›å»ºå¿«é€Ÿå¯åŠ¨è„šæœ¬
- [ ] ä»»åŠ¡3: åˆ›å»ºç»Ÿä¸€é…ç½®
- [ ] ä»»åŠ¡4: åˆ›å»ºç›‘æ§éªŒè¯å·¥å…·

### æœ¬å‘¨å®Œæˆï¼ˆå»ºè®®ï¼‰

- [ ] ä»»åŠ¡5: æ•°æ®æŒä¹…åŒ–
- [ ] ä»»åŠ¡6: å‘Šè­¦é€šçŸ¥ç³»ç»Ÿ

---

## äº”ã€éªŒè¯å‘½ä»¤

```bash
# 1. å¯åŠ¨æ‰€æœ‰æœåŠ¡
./start-all.sh

# 2. æ£€æŸ¥çŠ¶æ€
./check-status.sh

# 3. éªŒè¯ç›‘æ§
./scripts/verify-monitoring.sh

# 4. æŸ¥çœ‹æ—¥å¿—
tail -f logs/*.log

# 5. åœæ­¢æœåŠ¡
./stop-all.sh
```

---

## å…­ã€é¢„æœŸæ•ˆæœ

å®Œæˆä¸Šè¿°ä¼˜åŒ–åï¼š

1. **ä¸€é”®å¯åŠ¨**: `./start-all.sh` å¯åŠ¨æ‰€æœ‰æœåŠ¡
2. **ç»Ÿä¸€ç›‘æ§**: è®¿é—® `http://0.0.0.0:5500/api/v1/monitor/overview` æŸ¥çœ‹äº”å±‚ç›‘æ§
3. **æ•°æ®æŒä¹…åŒ–**: ç›‘æ§æ•°æ®ä¿å­˜åˆ°SQLiteï¼Œæ”¯æŒå†å²æŸ¥è¯¢
4. **è‡ªåŠ¨å‘Šè­¦**: å¼‚å¸¸è‡ªåŠ¨è§¦å‘é€šçŸ¥
5. **çŠ¶æ€éªŒè¯**: `./scripts/verify-monitoring.sh` ä¸€é”®éªŒè¯

---

**ä¸‹ä¸€æ­¥**: æŒ‰æ¸…å•é€æ­¥å®æ–½ï¼Œæ¯å®Œæˆä¸€é¡¹è¿›è¡ŒéªŒè¯æµ‹è¯•ã€‚
