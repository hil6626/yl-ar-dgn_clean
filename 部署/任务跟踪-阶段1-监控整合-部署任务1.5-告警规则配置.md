# 阶段1 - 任务1.5: 告警规则配置 - 详细部署文档

**任务ID:** 1.5  
**任务名称:** 告警规则配置  
**优先级:** P1（重要）  
**预计工时:** 3小时  
**状态:** 待执行  
**前置依赖:** 任务1.4完成（统一监控面板已配置）

---

## 一、任务目标

配置告警规则，实现节点离线、服务异常、性能阈值等告警的自动检测和通知。

## 二、部署内容

### 2.1 创建/修改文件清单

| 序号 | 文件路径 | 操作类型 | 说明 |
|------|----------|----------|------|
| 1 | `YL-monitor/app/services/alert_manager.py` | 新建 | 告警管理器 |
| 2 | `YL-monitor/app/config/alert_rules.yaml` | 新建 | 告警规则配置 |
| 3 | `YL-monitor/app/models/alert.py` | 新建 | 告警数据模型 |
| 4 | `YL-monitor/app/routes/alerts.py` | 新建 | 告警API路由 |
| 5 | `YL-monitor/app/services/ar_monitor.py` | 修改 | 集成告警触发 |

### 2.2 详细代码实现

#### 文件1: YL-monitor/app/services/alert_manager.py

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
告警管理器
提供告警规则管理、触发、通知等功能
"""

import os
import yaml
import asyncio
import logging
import smtplib
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

logger = logging.getLogger('AlertManager')


class AlertLevel(Enum):
    """告警级别"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class AlertStatus(Enum):
    """告警状态"""
    ACTIVE = "active"
    ACKNOWLEDGED = "acknowledged"
    RESOLVED = "resolved"


@dataclass
class AlertRule:
    """告警规则"""
    rule_id: str
    name: str
    description: str
    level: AlertLevel
    condition: str  # 条件表达式
    duration: int  # 持续时间（秒）
    enabled: bool = True
    channels: List[str] = field(default_factory=list)
    cooldown: int = 300  # 冷却时间（秒）
    
    # 运行时状态
    last_triggered: Optional[datetime] = None
    trigger_count: int = 0


@dataclass
class Alert:
    """告警实例"""
    alert_id: str
    rule_id: str
    title: str
    message: str
    level: AlertLevel
    status: AlertStatus
    source: str  # 告警来源
    created_at: datetime
    acknowledged_at: Optional[datetime] = None
    resolved_at: Optional[datetime] = None
    acknowledged_by: Optional[str] = None
    metadata: Dict = field(default_factory=dict)


class AlertManager:
    """
    告警管理器
    """
    
    def __init__(self, config_path: Optional[str] = None):
        self.rules: Dict[str, AlertRule] = {}
        self.active_alerts: Dict[str, Alert] = {}
        self.alert_history: List[Alert] = []
        self.max_history = 1000
        
        self.config_path = config_path or self._find_config()
        self.notification_channels: Dict[str, Callable] = {}
        
        # 加载配置
        self._load_config()
        self._setup_channels()
        
    def _find_config(self) -> Optional[str]:
        """查找配置文件"""
        possible_paths = [
            Path(__file__).parent.parent / 'config' / 'alert_rules.yaml',
            Path.cwd() / 'config' / 'alert_rules.yaml',
        ]
        
        for path in possible_paths:
            if path.exists():
                return str(path)
        return None
    
    def _load_config(self):
        """加载告警规则配置"""
        if not self.config_path or not Path(self.config_path).exists():
            logger.warning("未找到告警规则配置，使用默认规则")
            self._create_default_rules()
            return
            
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            for rule_config in config.get('rules', []):
                rule = AlertRule(
                    rule_id=rule_config['rule_id'],
                    name=rule_config['name'],
                    description=rule_config.get('description', ''),
                    level=AlertLevel(rule_config['level']),
                    condition=rule_config['condition'],
                    duration=rule_config.get('duration', 60),
                    enabled=rule_config.get('enabled', True),
                    channels=rule_config.get('channels', ['log']),
                    cooldown=rule_config.get('cooldown', 300)
                )
                self.rules[rule.rule_id] = rule
                logger.info(f"加载告警规则: {rule.rule_id}")
                
        except Exception as e:
            logger.error(f"加载告警配置失败: {e}")
            self._create_default_rules()
    
    def _create_default_rules(self):
        """创建默认告警规则"""
        default_rules = [
            AlertRule(
                rule_id='node_offline',
                name='节点离线',
                description='节点连续多次健康检查失败',
                level=AlertLevel.ERROR,
                condition='status == "offline"',
                duration=0,
                channels=['log', 'webhook']
            ),
            AlertRule(
                rule_id='high_cpu',
                name='CPU使用率过高',
                description='节点CPU使用率超过80%',
                level=AlertLevel.WARNING,
                condition='cpu_percent > 80',
                duration=300,
                channels=['log']
            ),
            AlertRule(
                rule_id='high_memory',
                name='内存使用率过高',
                description='节点内存使用率超过85%',
                level=AlertLevel.WARNING,
                condition='memory_percent > 85',
                duration=300,
                channels=['log']
            ),
            AlertRule(
                rule_id='service_unavailable',
                name='服务不可用',
                description='关键服务无法访问',
                level=AlertLevel.CRITICAL,
                condition='health_check_failed',
                duration=0,
                channels=['log', 'webhook', 'email']
            )
        ]
        
        for rule in default_rules:
            self.rules[rule.rule_id] = rule
        
        # 保存默认配置
        if self.config_path:
            self._save_config()
    
    def _save_config(self):
        """保存配置"""
        try:
            config = {
                'rules': [
                    {
                        'rule_id': r.rule_id,
                        'name': r.name,
                        'description': r.description,
                        'level': r.level.value,
                        'condition': r.condition,
                        'duration': r.duration,
                        'enabled': r.enabled,
                        'channels': r.channels,
                        'cooldown': r.cooldown
                    }
                    for r in self.rules.values()
                ]
            }
            
            Path(self.config_path).parent.mkdir(parents=True, exist_ok=True)
            with open(self.config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
                
        except Exception as e:
            logger.error(f"保存配置失败: {e}")
    
    def _setup_channels(self):
        """设置通知渠道"""
        self.notification_channels = {
            'log': self._send_log_notification,
            'webhook': self._send_webhook_notification,
            'email': self._send_email_notification
        }
    
    def _send_log_notification(self, alert: Alert):
        """日志通知"""
        level_map = {
            AlertLevel.INFO: logging.INFO,
            AlertLevel.WARNING: logging.WARNING,
            AlertLevel.ERROR: logging.ERROR,
            AlertLevel.CRITICAL: logging.CRITICAL
        }
        
        logger.log(
            level_map.get(alert.level, logging.INFO),
            f"[ALERT] {alert.title}: {alert.message}"
        )
    
    def _send_webhook_notification(self, alert: Alert):
        """Webhook通知"""
        webhook_url = os.getenv('ALERT_WEBHOOK_URL')
        if not webhook_url:
            logger.warning("未配置Webhook URL")
            return
            
        try:
            payload = {
                'alert_id': alert.alert_id,
                'title': alert.title,
                'message': alert.message,
                'level': alert.level.value,
                'source': alert.source,
                'timestamp': alert.created_at.isoformat()
            }
            
            response = requests.post(
                webhook_url,
                json=payload,
                timeout=10
            )
            
            if response.status_code == 200:
                logger.info(f"Webhook通知发送成功: {alert.alert_id}")
            else:
                logger.warning(f"Webhook通知失败: HTTP {response.status_code}")
                
        except Exception as e:
            logger.error(f"Webhook通知异常: {e}")
    
    def _send_email_notification(self, alert: Alert):
        """邮件通知"""
        smtp_server = os.getenv('ALERT_SMTP_SERVER')
        smtp_port = int(os.getenv('ALERT_SMTP_PORT', 587))
        username = os.getenv('ALERT_SMTP_USERNAME')
        password = os.getenv('ALERT_SMTP_PASSWORD')
        to_addresses = os.getenv('ALERT_EMAIL_TO', '').split(',')
        
        if not all([smtp_server, username, password, to_addresses]):
            logger.warning("邮件配置不完整")
            return
            
        try:
            msg = MIMEMultipart()
            msg['From'] = username
            msg['To'] = ', '.join(to_addresses)
            msg['Subject'] = f"[{alert.level.value.upper()}] {alert.title}"
            
            body = f"""
            告警详情:
            
            告警ID: {alert.alert_id}
            标题: {alert.title}
            级别: {alert.level.value}
            来源: {alert.source}
            时间: {alert.created_at}
            
            详情:
            {alert.message}
            """
            
            msg.attach(MIMEText(body, 'plain', 'utf-8'))
            
            server = smtplib.SMTP(smtp_server, smtp_port)
            server.starttls()
            server.login(username, password)
            server.send_message(msg)
            server.quit()
            
            logger.info(f"邮件通知发送成功: {alert.alert_id}")
            
        except Exception as e:
            logger.error(f"邮件通知异常: {e}")
    
    async def evaluate_rules(self, node_id: str, node_data: dict):
        """评估告警规则"""
        for rule in self.rules.values():
            if not rule.enabled:
                continue
            
            # 检查冷却时间
            if rule.last_triggered:
                cooldown_end = rule.last_triggered + timedelta(seconds=rule.cooldown)
                if datetime.utcnow() < cooldown_end:
                    continue
            
            # 评估条件
            try:
                if self._evaluate_condition(rule.condition, node_data):
                    await self._trigger_alert(rule, node_id, node_data)
            except Exception as e:
                logger.error(f"评估规则 {rule.rule_id} 失败: {e}")
    
    def _evaluate_condition(self, condition: str, data: dict) -> bool:
        """评估条件表达式"""
        # 简单的条件评估
        try:
            # 支持的条件格式:
            # - status == "offline"
            # - cpu_percent > 80
            # - memory_percent > 85
            
            if '==' in condition:
                key, value = condition.split('==')
                key = key.strip()
                value = value.strip().strip('"').strip("'")
                return str(data.get(key)) == value
            
            elif '>' in condition:
                key, value = condition.split('>')
                key = key.strip()
                value = float(value.strip())
                return float(data.get(key, 0)) > value
            
            elif '<' in condition:
                key, value = condition.split('<')
                key = key.strip()
                value = float(value.strip())
                return float(data.get(key, 0)) < value
            
            else:
                # 特殊条件
                if condition == 'health_check_failed':
                    return data.get('consecutive_fails', 0) > 0
                
        except Exception as e:
            logger.error(f"条件评估错误: {e}")
            return False
        
        return False
    
    async def _trigger_alert(self, rule: AlertRule, node_id: str, node_data: dict):
        """触发告警"""
        alert_id = f"{rule.rule_id}-{node_id}-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}"
        
        # 检查是否已存在相同告警
        existing_key = f"{rule.rule_id}-{node_id}"
        if existing_key in self.active_alerts:
            logger.debug(f"告警已存在: {existing_key}")
            return
        
        # 创建告警
        alert = Alert(
            alert_id=alert_id,
            rule_id=rule.rule_id,
            title=f"{rule.name} - {node_id}",
            message=rule.description,
            level=rule.level,
            status=AlertStatus.ACTIVE,
            source=node_id,
            created_at=datetime.utcnow(),
            metadata={
                'node_data': node_data,
                'rule_data': {
                    'condition': rule.condition,
                    'duration': rule.duration
                }
            }
        )
        
        self.active_alerts[existing_key] = alert
        self.alert_history.append(alert)
        
        # 限制历史记录
        if len(self.alert_history) > self.max_history:
            self.alert_history = self.alert_history[-self.max_history:]
        
        # 更新规则统计
        rule.last_triggered = datetime.utcnow()
        rule.trigger_count += 1
        
        # 发送通知
        for channel in rule.channels:
            handler = self.notification_channels.get(channel)
            if handler:
                try:
                    if asyncio.iscoroutinefunction(handler):
                        await handler(alert)
                    else:
                        handler(alert)
                except Exception as e:
                    logger.error(f"通知发送失败 ({channel}): {e}")
        
        logger.warning(f"告警触发: {alert.title} ({alert.level.value})")
        
        # 广播WebSocket
        try:
            from app.websocket.ar_ws import ws_manager
            await ws_manager.broadcast_alert({
                'alert_id': alert.alert_id,
                'title': alert.title,
                'message': alert.message,
                'level': alert.level.value,
                'timestamp': alert.created_at.isoformat()
            })
        except Exception as e:
            logger.error(f"WebSocket广播失败: {e}")
    
    def acknowledge_alert(self, alert_key: str, user: str) -> bool:
        """确认告警"""
        if alert_key not in self.active_alerts:
            return False
        
        alert = self.active_alerts[alert_key]
        alert.status = AlertStatus.ACKNOWLEDGED
        alert.acknowledged_at = datetime.utcnow()
        alert.acknowledged_by = user
        
        logger.info(f"告警已确认: {alert.alert_id} by {user}")
        return True
    
    def resolve_alert(self, alert_key: str) -> bool:
        """解决告警"""
        if alert_key not in self.active_alerts:
            return False
        
        alert = self.active_alerts[alert_key]
        alert.status = AlertStatus.RESOLVED
        alert.resolved_at = datetime.utcnow()
        
        # 从活动告警中移除
        del self.active_alerts[alert_key]
        
        logger.info(f"告警已解决: {alert.alert_id}")
        return True
    
    def get_active_alerts(self, level: Optional[AlertLevel] = None) -> List[Alert]:
        """获取活动告警"""
        alerts = list(self.active_alerts.values())
        if level:
            alerts = [a for a in alerts if a.level == level]
        return sorted(alerts, key=lambda x: x.created_at, reverse=True)
    
    def get_alert_history(
        self,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
        level: Optional[AlertLevel] = None
    ) -> List[Alert]:
        """获取告警历史"""
        alerts = self.alert_history
        
        if start_time:
            alerts = [a for a in alerts if a.created_at >= start_time]
        if end_time:
            alerts = [a for a in alerts if a.created_at <= end_time]
        if level:
            alerts = [a for a in alerts if a.level == level]
        
        return sorted(alerts, key=lambda x: x.created_at, reverse=True)
    
    def get_alert_stats(self) -> dict:
        """获取告警统计"""
        total = len(self.alert_history)
        active = len(self.active_alerts)
        
        by_level = {
            'info': 0,
            'warning': 0,
            'error': 0,
            'critical': 0
        }
        
        for alert in self.alert_history:
            by_level[alert.level.value] += 1
        
        return {
            'total': total,
            'active': active,
            'by_level': by_level,
            'acknowledged': len([a for a in self.alert_history if a.status == AlertStatus.ACKNOWLEDGED]),
            'resolved': len([a for a in self.alert_history if a.status == AlertStatus.RESOLVED])
        }
```

#### 文件2: YL-monitor/app/config/alert_rules.yaml

```yaml
# 告警规则配置

rules:
  # 节点离线告警
  - rule_id: node_offline
    name: 节点离线
    description: 节点连续多次健康检查失败，已标记为离线
    level: error
    condition: 'status == "offline"'
    duration: 0
    enabled: true
    channels:
      - log
      - webhook
    cooldown: 300

  # CPU使用率告警
  - rule_id: high_cpu
    name: CPU使用率过高
    description: 节点CPU使用率超过80%，持续5分钟
    level: warning
    condition: 'cpu_percent > 80'
    duration: 300
    enabled: true
    channels:
      - log
    cooldown: 600

  # 内存使用率告警
  - rule_id: high_memory
    name: 内存使用率过高
    description: 节点内存使用率超过85%，持续5分钟
    level: warning
    condition: 'memory_percent > 85'
    duration: 300
    enabled: true
    channels:
      - log
    cooldown: 600

  # 服务不可用告警
  - rule_id: service_unavailable
    name: 服务不可用
    description: 关键服务无法访问，需要立即处理
    level: critical
    condition: 'health_check_failed'
    duration: 0
    enabled: true
    channels:
      - log
      - webhook
      - email
    cooldown: 60

  # 心跳超时告警
  - rule_id: heartbeat_timeout
    name: 心跳超时
    description: 节点超过2分钟未上报心跳
    level: warning
    condition: 'heartbeat_timeout'
    duration: 120
    enabled: true
    channels:
      - log
    cooldown: 300

# 通知渠道配置
channels:
  webhook:
    enabled: false
    url: ""
  
  email:
    enabled: false
    smtp_server: ""
    smtp_port: 587
    username: ""
    password: ""
    to_addresses: []

# 告警抑制配置
suppression:
  enabled: true
  max_alerts_per_hour: 10
  group_similar: true
```

#### 文件3: YL-monitor/app/models/alert.py

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
告警数据模型
"""

from pydantic import BaseModel
from typing import Optional, Dict, List
from datetime import datetime
from enum import Enum


class AlertLevel(str, Enum):
    """告警级别"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class AlertStatus(str, Enum):
    """告警状态"""
    ACTIVE = "active"
    ACKNOWLEDGED = "acknowledged"
    RESOLVED = "resolved"


class AlertCreate(BaseModel):
    """创建告警请求"""
    rule_id: str
    title: str
    message: str
    level: AlertLevel
    source: str
    metadata: Optional[Dict] = None


class AlertResponse(BaseModel):
    """告警响应"""
    alert_id: str
    rule_id: str
    title: str
    message: str
    level: AlertLevel
    status: AlertStatus
    source: str
    created_at: datetime
    acknowledged_at: Optional[datetime] = None
    resolved_at: Optional[datetime] = None
    acknowledged_by: Optional[str] = None
    metadata: Optional[Dict] = None


class AlertAcknowledge(BaseModel):
    """确认告警请求"""
    user: str


class AlertStats(BaseModel):
    """告警统计"""
    total: int
    active: int
    by_level: Dict[str, int]
    acknowledged: int
    resolved: int


class AlertRuleConfig(BaseModel):
    """告警规则配置"""
    rule_id: str
    name: str
    description: str
    level: AlertLevel
    condition: str
    duration: int
    enabled: bool
    channels: List[str]
    cooldown: int
```

#### 文件4: YL-monitor/app/routes/alerts.py

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
告警路由
提供告警管理API
"""

from fastapi import APIRouter, HTTPException, Depends, Query
from typing import List, Optional
from datetime import datetime

from app.models.alert import (
    AlertResponse, AlertAcknowledge, AlertStats,
    AlertLevel, AlertStatus
)
from app.services.alert_manager import AlertManager, AlertLevel as ALLevel

router = APIRouter(prefix="/api/alerts", tags=["告警管理"])


def get_alert_manager() -> AlertManager:
    """获取告警管理器实例"""
    # 这里应该从应用状态获取
    from app.main import app
    return getattr(app.state, 'alert_manager', None)


@router.get("", response_model=List[AlertResponse])
async def list_alerts(
    status: Optional[AlertStatus] = None,
    level: Optional[AlertLevel] = None,
    source: Optional[str] = None
):
    """获取告警列表"""
    manager = get_alert_manager()
    if not manager:
        raise HTTPException(status_code=503, detail="告警服务未初始化")
    
    alerts = manager.get_active_alerts()
    
    if status:
        alerts = [a for a in alerts if a.status.value == status]
    if level:
        alerts = [a for a in alerts if a.level.value == level]
    if source:
        alerts = [a for a in alerts if a.source == source]
    
    return [
        AlertResponse(
            alert_id=a.alert_id,
            rule_id=a.rule_id,
            title=a.title,
            message=a.message,
            level=AlertLevel(a.level.value),
            status=AlertStatus(a.status.value),
            source=a.source,
            created_at=a.created_at,
            acknowledged_at=a.acknowledged_at,
            resolved_at=a.resolved_at,
            acknowledged_by=a.acknowledged_by,
            metadata=a.metadata
        )
        for a in alerts
    ]


@router.get("/stats", response_model=AlertStats)
async def get_alert_stats():
    """获取告警统计"""
    manager = get_alert_manager()
    if not manager:
        raise HTTPException(status_code=503, detail="告警服务未初始化")
    
    stats = manager.get_alert_stats()
    return AlertStats(**stats)


@router.post("/{alert_key}/acknowledge")
async def acknowledge_alert(alert_key: str, ack: AlertAcknowledge):
    """确认告警"""
    manager = get_alert_manager()
    if not manager:
        raise HTTPException(status_code=503, detail="告警服务未初始化")
    
    if manager.acknowledge_alert(alert_key, ack.user):
        return {"status": "success", "message": "告警已确认"}
    else:
        raise HTTPException(status_code=404, detail="告警不存在")


@router.post("/{alert_key}/resolve")
async def resolve_alert(alert_key: str):
    """解决告警"""
    manager = get_alert_manager()
    if not manager:
        raise HTTPException(status_code=503, detail="告警服务未初始化")
    
    if manager.resolve_alert(alert_key):
        return {"status": "success", "message": "告警已解决"}
    else:
        raise HTTPException(status_code=404, detail="告警不存在")


@router.get("/history", response_model=List[AlertResponse])
async def get_alert_history(
    start_time: Optional[datetime] = None,
    end_time: Optional[datetime] = None,
    level: Optional[AlertLevel] = None,
    limit: int = Query(100, ge=1, le=1000)
):
    """获取告警历史"""
    manager = get_alert_manager()
    if not manager:
        raise HTTPException(status_code=503, detail="告警服务未初始化")
    
    alerts = manager.get_alert_history(start_time, end_time, ALLevel(level) if level else None)
    alerts = alerts[:limit]
    
    return [
        AlertResponse(
            alert_id=a.alert_id,
            rule_id=a.rule_id,
            title=a.title,
            message=a.message,
            level=AlertLevel(a.level.value),
            status=AlertStatus(a.status.value),
            source=a.source,
            created_at=a.created_at,
            acknowledged_at=a.acknowledged_at,
            resolved_at=a.resolved_at,
            acknowledged_by=a.acknowledged_by,
            metadata=a.metadata
        )
        for a in alerts
    ]
```

#### 文件5: 修改 YL-monitor/app/services/ar_monitor.py

在节点检查中集成告警：

```python
# 在 ARMonitor 类中添加
async def _check_node(self, node: NodeInfo):
    # ... 原有检查逻辑 ...
    
    # 评估告警规则
    try:
        from app.main import app
        alert_manager = getattr(app.state, 'alert_manager', None)
        if alert_manager:
            node_data = {
                'status': node.status,
                'consecutive_fails': node.consecutive_fails,
                **node.metadata
            }
            await alert_manager.evaluate_rules(node.node_id, node_data)
    except Exception as e:
        logger.error(f"告警评估失败: {e}")
```

## 三、关联内容修复

### 3.1 需要同步修复的文件

| 文件 | 修复内容 | 原因 |
|------|----------|------|
| `YL-monitor/app/main.py` | 初始化告警管理器 | 服务启动 |
| `YL-monitor/app/routes/__init__.py` | 注册告警路由 | API集成 |
| `YL-monitor/app/services/ar_monitor.py` | 集成告警触发 | 自动检测 |

### 3.2 详细修复说明

#### 修复1: YL-monitor/app/main.py

```python
# 在 lifespan 中添加告警管理器初始化

# 初始化告警管理器
try:
    from app.services.alert_manager import AlertManager
    alert_manager = AlertManager()
    app.state.alert_manager = alert_manager
    logger.info(f"✓ 告警管理器已启动，加载了 {len(alert_manager.rules)} 条规则")
except Exception as e:
    logger.error(f"✗ 告警管理器启动失败: {e}")
    app.state.alert_manager = None
```

#### 修复2: YL-monitor/app/routes/__init__.py

```python
from app.routes import alerts  # 新增

def register_routers(app):
    # ... 其他路由 ...
    app.include_router(alerts.router)
```

## 四、部署执行步骤

### 4.1 执行前检查

```bash
# 1. 确认任务1.4已完成
curl http://localhost:5500/api/ar/dashboard

# 2. 检查配置目录
ls -la YL-monitor/app/config/
```

### 4.2 部署执行

```bash
# 1. 创建告警管理文件
# YL-monitor/app/services/alert_manager.py
# YL-monitor/app/models/alert.py
# YL-monitor/app/routes/alerts.py
# YL-monitor/app/config/alert_rules.yaml

# 2. 修改关联文件
# YL-monitor/app/main.py
# YL-monitor/app/routes/__init__.py
# YL-monitor/app/services/ar_monitor.py

# 3. 重启服务
cd YL-monitor
uvicorn app.main:app --reload --host 0.0.0.0 --port 5500
```

### 4.3 部署验证

```bash
# 1. 检查告警规则
curl http://localhost:5500/api/alerts/stats

# 2. 检查活动告警
curl http://localhost:5500/api/alerts

# 3. 测试告警触发（停止AR-backend服务）
# 等待几分钟后检查告警

# 4. 检查告警历史
curl http://localhost:5500/api/alerts/history
```

## 五、常见问题及解决

### 问题1: 告警不触发

**现象:** 节点离线但无告警

**解决:**
```bash
# 检查规则是否启用
cat YL-monitor/app/config/alert_rules.yaml

# 检查告警管理器日志
grep "ALERT" YL-monitor/logs/app.log
```

### 问题2: 通知发送失败

**现象:** 告警产生但无通知

**解决:**
```bash
# 检查环境变量
echo $ALERT_WEBHOOK_URL
echo $ALERT_SMTP_SERVER

# 检查通知渠道配置
```

### 问题3: 告警风暴

**现象:** 大量重复告警

**解决:**
```yaml
# 调整冷却时间
cooldown: 600  # 增加到10分钟

# 启用告警抑制
suppression:
  enabled: true
  max_alerts_per_hour: 10
```

## 六、验证清单

- [ ] 告警管理器创建完成
- [ ] 告警规则配置完成
- [ ] 告警模型创建完成
- [ ] 告警路由创建完成
- [ ] 关联文件修改完成
- [ ] 告警规则加载正常
- [ ] 告警触发正常
- [ ] 告警通知正常
- [ ] 告警确认/解决正常
- [ ] 告警统计正常

## 七、下一步

完成本任务后，继续执行 **任务1.6: 集成测试验证**

查看文档: `部署/任务跟踪-阶段1-监控整合-部署任务1.6-集成测试验证.md`
