# 部署任务6.2: AR-backend人脸合成功能验证

**任务ID:** 6.2  
**所属阶段:** 阶段6 - 核心业务功能验证  
**任务名称:** AR-backend人脸合成功能验证  
**优先级:** P0（最高优先级）  
**关键性:** 阻塞性  
**预计工时:** 6小时  
**负责人:** AI算法工程师  
**前置依赖:** 任务6.1完成  
**状态:** 待开始

---

## 一、任务目标

验证AR-backend人脸合成功能，确保Deep-Live-Cam引擎、DeepFaceLab集成、FaceSwap功能和人脸检测功能正常。

---

## 二、工作内容

1. Deep-Live-Cam引擎测试
2. DeepFaceLab集成测试
3. FaceSwap功能测试
4. 人脸检测和关键点识别
5. 合成效果质量评估

---

## 三、实施步骤

### 步骤1: 检查人脸合成模型

```bash
# 1. 检查模型文件目录
echo "检查人脸合成模型..."
ls -la /home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend/models/face_swap/ 2>/dev/null || echo "face_swap模型目录不存在"
ls -la /home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend/models/deep_live_cam/ 2>/dev/null || echo "deep_live_cam模型目录不存在"

# 2. 检查模型文件完整性
echo "检查模型文件..."
find /home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend/models -name "*.onnx" -o -name "*.pth" -o -name "*.ckpt" | head -20
```

### 步骤2: 测试人脸检测

```bash
# 创建人脸检测测试脚本
cat > /tmp/test_face_detection.py << 'EOF'
#!/usr/bin/env python3
import cv2
import sys
import time

sys.path.insert(0, '/home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend')

def test_face_detection():
    print("=" * 50)
    print("人脸检测功能测试")
    print("=" * 50)
    
    try:
        from app.core.face_detector import FaceDetector
        detector = FaceDetector()
        print("✓ 人脸检测器初始化成功")
    except Exception as e:
        print(f"✗ 人脸检测器初始化失败: {e}")
        return False
    
    # 打开摄像头
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("✗ 无法打开摄像头")
        return False
    
    print("✓ 摄像头已打开")
    
    # 测试参数
    test_frames = 100
    detection_count = 0
    total_faces = 0
    detection_times = []
    
    print(f"\n开始测试 {test_frames} 帧...")
    
    for i in range(test_frames):
        ret, frame = cap.read()
        if not ret:
            continue
        
        # 检测人脸
        start = time.time()
        faces = detector.detect(frame)
        end = time.time()
        
        detection_times.append((end - start) * 1000)
        
        if faces:
            detection_count += 1
            total_faces += len(faces)
        
        if (i + 1) % 20 == 0:
            print(f"  已处理 {i + 1}/{test_frames} 帧")
    
    cap.release()
    
    # 计算统计信息
    import statistics
    avg_time = statistics.mean(detection_times)
    detection_rate = detection_count / test_frames
    
    print(f"\n" + "=" * 50)
    print("人脸检测结果:")
    print(f"  测试帧数: {test_frames}")
    print(f"  检测到人脸的帧数: {detection_count}")
    print(f"  检测率: {detection_rate * 100:.2f}%")
    print(f"  检测到的人脸总数: {total_faces}")
    print(f"  平均检测时间: {avg_time:.2f}ms")
    print("=" * 50)
    
    # 验证结果
    success = detection_rate >= 0.90 and avg_time < 50  # 90%检测率，<50ms
    
    if success:
        print("✓ 人脸检测测试通过")
    else:
        print("✗ 人脸检测测试失败")
        if detection_rate < 0.90:
            print("  - 检测率低于90%")
        if avg_time >= 50:
            print("  - 检测时间超过50ms")
    
    return success

if __name__ == "__main__":
    success = test_face_detection()
    sys.exit(0 if success else 1)
EOF

# 执行测试
python3 /tmp/test_face_detection.py
```

### 步骤3: 测试Deep-Live-Cam

```bash
# 创建Deep-Live-Cam测试脚本
cat > /tmp/test_deep_live_cam.py << 'EOF'
#!/usr/bin/env python3
import cv2
import sys
import time
import os

sys.path.insert(0, '/home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend')

def test_deep_live_cam():
    print("=" * 50)
    print("Deep-Live-Cam引擎测试")
    print("=" * 50)
    
    try:
        from app.core.deep_live_cam import DeepLiveCam
        engine = DeepLiveCam()
        print("✓ Deep-Live-Cam引擎初始化成功")
    except Exception as e:
        print(f"✗ Deep-Live-Cam引擎初始化失败: {e}")
        return False
    
    # 检查模型加载
    if not engine.is_model_loaded():
        print("✗ 模型未加载")
        return False
    print("✓ 模型加载成功")
    
    # 创建测试目标人脸
    target_face_path = "/tmp/test_target_face.jpg"
    if not os.path.exists(target_face_path):
        print(f"⚠ 目标人脸图片不存在: {target_face_path}")
        print("  使用摄像头捕获作为目标...")
        
        cap = cv2.VideoCapture(0)
        ret, frame = cap.read()
        if ret:
            cv2.imwrite(target_face_path, frame)
            print(f"✓ 已保存目标人脸: {target_face_path}")
        cap.release()
    
    # 加载目标人脸
    try:
        engine.set_target_face(target_face_path)
        print(f"✓ 目标人脸加载成功")
    except Exception as e:
        print(f"✗ 目标人脸加载失败: {e}")
        return False
    
    # 测试实时合成
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("✗ 无法打开摄像头")
        return False
    
    print("\n开始实时合成测试 (10秒)...")
    
    test_duration = 10
    frame_count = 0
    success_count = 0
    processing_times = []
    
    start_time = time.time()
    
    while time.time() - start_time < test_duration:
        ret, frame = cap.read()
        if not ret:
            continue
        
        frame_count += 1
        
        # 执行合成
        try:
            process_start = time.time()
            result = engine.swap(frame)
            process_end = time.time()
            
            if result is not None:
                success_count += 1
                processing_times.append((process_end - process_start) * 1000)
            
            if frame_count % 30 == 0:
                print(f"  已处理 {frame_count} 帧")
                
        except Exception as e:
            print(f"  合成错误: {e}")
    
    cap.release()
    
    # 计算统计信息
    if processing_times:
        import statistics
        avg_time = statistics.mean(processing_times)
        max_time = max(processing_times)
        success_rate = success_count / frame_count if frame_count > 0 else 0
        
        print(f"\n" + "=" * 50)
        print("Deep-Live-Cam测试结果:")
        print(f"  测试时长: {test_duration}秒")
        print(f"  处理帧数: {frame_count}")
        print(f"  成功合成: {success_count}")
        print(f"  成功率: {success_rate * 100:.2f}%")
        print(f"  平均处理时间: {avg_time:.2f}ms")
        print(f"  最大处理时间: {max_time:.2f}ms")
        print("=" * 50)
        
        # 验证结果
        success = success_rate >= 0.85 and avg_time < 100  # 85%成功率，<100ms
        
        if success:
            print("✓ Deep-Live-Cam测试通过")
        else:
            print("✗ Deep-Live-Cam测试失败")
            if success_rate < 0.85:
                print("  - 成功率低于85%")
            if avg_time >= 100:
                print("  - 处理时间超过100ms")
        
        return success
    else:
        print("✗ 没有成功处理的帧")
        return False

if __name__ == "__main__":
    success = test_deep_live_cam()
    sys.exit(0 if success else 1)
EOF

# 执行测试
python3 /tmp/test_deep_live_cam.py
```

### 步骤4: 测试FaceSwap

```bash
# 创建FaceSwap测试脚本
cat > /tmp/test_faceswap.py << 'EOF'
#!/usr/bin/env python3
import cv2
import sys
import time
import os

sys.path.insert(0, '/home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend')

def test_faceswap():
    print("=" * 50)
    print("FaceSwap功能测试")
    print("=" * 50)
    
    try:
        from app.core.face_swap import FaceSwapModel
        model = FaceSwapModel()
        print("✓ FaceSwap模型初始化成功")
    except Exception as e:
        print(f"✗ FaceSwap模型初始化失败: {e}")
        return False
    
    # 检查模型加载
    if not model.is_loaded():
        print("✗ 模型未加载")
        return False
    print("✓ 模型加载成功")
    
    # 创建测试图片
    swap_face_path = "/tmp/test_swap_face.jpg"
    if not os.path.exists(swap_face_path):
        cap = cv2.VideoCapture(0)
        ret, frame = cap.read()
        if ret:
            cv2.imwrite(swap_face_path, frame)
            print(f"✓ 已保存交换人脸: {swap_face_path}")
        cap.release()
    
    # 加载交换人脸
    try:
        model.set_swap_face(swap_face_path)
        print(f"✓ 交换人脸加载成功")
    except Exception as e:
        print(f"✗ 交换人脸加载失败: {e}")
        return False
    
    # 测试实时交换
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("✗ 无法打开摄像头")
        return False
    
    print("\n开始FaceSwap测试 (10秒)...")
    
    test_duration = 10
    frame_count = 0
    swap_count = 0
    processing_times = []
    
    start_time = time.time()
    
    while time.time() - start_time < test_duration:
        ret, frame = cap.read()
        if not ret:
            continue
        
        frame_count += 1
        
        # 执行交换
        try:
            process_start = time.time()
            result = model.swap_faces(frame)
            process_end = time.time()
            
            if result is not None:
                swap_count += 1
                processing_times.append((process_end - process_start) * 1000)
            
            if frame_count % 30 == 0:
                print(f"  已处理 {frame_count} 帧")
                
        except Exception as e:
            print(f"  交换错误: {e}")
    
    cap.release()
    
    # 计算统计信息
    if processing_times:
        import statistics
        avg_time = statistics.mean(processing_times)
        swap_rate = swap_count / frame_count if frame_count > 0 else 0
        
        print(f"\n" + "=" * 50)
        print("FaceSwap测试结果:")
        print(f"  测试时长: {test_duration}秒")
        print(f"  处理帧数: {frame_count}")
        print(f"  成功交换: {swap_count}")
        print(f"  成功率: {swap_rate * 100:.2f}%")
        print(f"  平均处理时间: {avg_time:.2f}ms")
        print("=" * 50)
        
        # 验证结果
        success = swap_rate >= 0.80 and avg_time < 100
        
        if success:
            print("✓ FaceSwap测试通过")
        else:
            print("✗ FaceSwap测试失败")
            if swap_rate < 0.80:
                print("  - 成功率低于80%")
            if avg_time >= 100:
                print("  - 处理时间超过100ms")
        
        return success
    else:
        print("✗ 没有成功交换的帧")
        return False

if __name__ == "__main__":
    success = test_faceswap()
    sys.exit(0 if success else 1)
EOF

# 执行测试
python3 /tmp/test_faceswap.py
```

### 步骤5: 合成效果质量评估

```bash
# 创建质量评估脚本
cat > /tmp/evaluate_face_swap_quality.py << 'EOF'
#!/usr/bin/env python3
import cv2
import sys
import numpy as np

sys.path.insert(0, '/home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend')

def evaluate_quality():
    print("=" * 50)
    print("人脸合成质量评估")
    print("=" * 50)
    
    try:
        from app.core.face_swap import FaceSwapModel
        model = FaceSwapModel()
    except Exception as e:
        print(f"✗ 模型初始化失败: {e}")
        return False
    
    # 捕获测试帧
    cap = cv2.VideoCapture(0)
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        print("✗ 无法捕获测试帧")
        return False
    
    # 执行合成
    try:
        result = model.swap_faces(frame)
        
        if result is None:
            print("✗ 合成失败")
            return False
        
        # 质量评估指标
        print("\n质量评估指标:")
        
        # 1. 亮度一致性
        original_brightness = np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))
        result_brightness = np.mean(cv2.cvtColor(result, cv2.COLOR_BGR2GRAY))
        brightness_diff = abs(original_brightness - result_brightness)
        print(f"  亮度差异: {brightness_diff:.2f} (目标: <30)")
        
        # 2. 色彩一致性
        original_color = np.mean(frame, axis=(0, 1))
        result_color = np.mean(result, axis=(0, 1))
        color_diff = np.mean(np.abs(original_color - result_color))
        print(f"  色彩差异: {color_diff:.2f} (目标: <50)")
        
        # 3. 清晰度
        original_lap = cv2.Laplacian(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), cv2.CV_64F).var()
        result_lap = cv2.Laplacian(cv2.cvtColor(result, cv2.COLOR_BGR2GRAY), cv2.CV_64F).var()
        clarity_ratio = result_lap / original_lap if original_lap > 0 else 0
        print(f"  清晰度比例: {clarity_ratio:.2f} (目标: >0.8)")
        
        # 4. 结构相似性
        from skimage.metrics import structural_similarity as ssim
        gray_original = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray_result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)
        similarity = ssim(gray_original, gray_result)
        print(f"  结构相似性: {similarity:.4f} (目标: >0.7)")
        
        print("\n" + "=" * 50)
        
        # 综合评估
        quality_score = 0
        checks = [
            brightness_diff < 30,
            color_diff < 50,
            clarity_ratio > 0.8,
            similarity > 0.7
        ]
        
        quality_score = sum(checks) / len(checks) * 100
        
        print(f"质量评分: {quality_score:.1f}%")
        
        if quality_score >= 75:
            print("✓ 合成质量评估通过")
            return True
        else:
            print("✗ 合成质量评估失败")
            return False
            
    except Exception as e:
        print(f"✗ 质量评估错误: {e}")
        return False

if __name__ == "__main__":
    success = evaluate_quality()
    sys.exit(0 if success else 1)
EOF

# 执行质量评估
python3 /tmp/evaluate_face_swap_quality.py
```

---

## 四、验证步骤

### 验证清单

- [ ] 人脸检测器初始化成功
- [ ] 人脸检测率≥95%
- [ ] 检测时间<50ms
- [ ] Deep-Live-Cam引擎初始化成功
- [ ] 模型加载成功
- [ ] 实时合成成功率≥85%
- [ ] 单帧合成时间<100ms
- [ ] FaceSwap功能正常
- [ ] 合成效果自然，无明显边界
- [ ] 质量评分≥75%

### 验证命令

```bash
# 快速验证脚本
cat > /tmp/verify_task_6.2.sh << 'EOF'
#!/bin/bash
echo "========================================"
echo "任务6.2验证: AR-backend人脸合成"
echo "========================================"

errors=0

# 1. 检查模型文件
echo -n "检查模型文件... "
if [ -d "/home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend/models" ]; then
    model_count=$(find /home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend/models -type f \( -name "*.onnx" -o -name "*.pth" -o -name "*.ckpt" \) | wc -l)
    if [ $model_count -gt 0 ]; then
        echo "✓ 通过 (找到 $model_count 个模型文件)"
    else
        echo "⚠ 警告: 未找到模型文件"
    fi
else
    echo "⚠ 警告: 模型目录不存在"
fi

# 2. 检查人脸检测模块
echo -n "检查人脸检测模块... "
if python3 -c "import sys; sys.path.insert(0, '/home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend'); from app.core.face_detector import FaceDetector; print('OK')" 2>/dev/null; then
    echo "✓ 通过"
else
    echo "✗ 失败"
    errors=$((errors + 1))
fi

# 3. 检查Deep-Live-Cam模块
echo -n "检查Deep-Live-Cam模块... "
if python3 -c "import sys; sys.path.insert(0, '/home/vboxuser/桌面/项目部署/项目1/yl-ar-dgn_clean/AR-backend'); from app.core.deep_live_cam import DeepLiveCam; print('OK')" 2>/dev/null; then
    echo "✓ 通过"
else
    echo "✗ 失败"
    errors=$((errors + 1))
fi

echo "========================================"
if [ $errors -eq 0 ]; then
    echo "✓ 任务6.2基础验证通过"
    exit 0
else
    echo "✗ 任务6.2验证失败 ($errors 个错误)"
    exit 1
fi
EOF

chmod +x /tmp/verify_task_6.2.sh
/tmp/verify_task_6.2.sh
```

---

## 五、预期结果

### 成功标准

| 指标 | 目标值 | 验证方法 |
|------|--------|----------|
| 人脸检测率 | ≥95% | 检测测试 |
| 检测时间 | <50ms | 性能测试 |
| 模型加载 | 成功 | 初始化测试 |
| 合成成功率 | ≥85% | 实时测试 |
| 合成时间 | <100ms/帧 | 性能测试 |
| 质量评分 | ≥75% | 质量评估 |

### 交付物

- [ ] 人脸检测测试报告
- [ ] 合成性能测试报告
- [ ] 质量评估报告
- [ ] 验证通过标记

---

## 六、可能产生的问题及解决方案

| 问题 | 风险等级 | 产生原因 | 解决方式 | 预防方式 |
|------|----------|----------|----------|----------|
| 模型加载失败 | 高 | 模型文件缺失或损坏 | 1. 重新下载模型<br>2. 验证模型完整性<br>3. 使用备用模型 | 1. 模型版本管理<br>2. 自动下载脚本 |
| 合成效果差 | 高 | 模型质量或参数设置 | 1. 调整合成参数<br>2. 更换高质量模型<br>3. 预处理优化 | 1. 模型评估流程<br>2. 参数调优工具 |
| 合成速度慢 | 中 | GPU未启用或模型过大 | 1. 启用CUDA<br>2. 使用轻量级模型<br>3. 模型量化 | 1. 性能基准测试<br>2. 自动选择模型 |
| 人脸检测失败 | 中 | 光线或角度问题 | 1. 改善光线条件<br>2. 多角度检测<br>3. 预处理增强 | 1. 检测鲁棒性测试 |

---

## 七、执行检查点

- [ ] 人脸检测测试通过
- [ ] Deep-Live-Cam测试通过
- [ ] FaceSwap测试通过
- [ ] 合成效果评估通过
- [ ] 性能基准达标

---

## 八、关联文档

- [任务跟踪-阶段6-核心业务功能验证.md](./任务跟踪-阶段6-核心业务功能验证.md)
- [任务跟踪-阶段6-核心业务功能验证-部署任务6.1-AR-backend实时视频处理验证.md](./任务跟踪-阶段6-核心业务功能验证-部署任务6.1-AR-backend实时视频处理验证.md)
- [任务跟踪-阶段6-核心业务功能验证-部署任务6.3-AR-backend音频处理功能验证.md](./任务跟踪-阶段6-核心业务功能验证-部署任务6.3-AR-backend音频处理功能验证.md)

---

**创建时间:** 2026-02-11  
**最后更新:** 2026-02-11
