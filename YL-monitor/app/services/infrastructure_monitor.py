#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºç¡€è®¾æ–½å±‚ç›‘æ§å™¨
æä¾›è¿›ç¨‹çº§ã€ç«¯å£çº§ã€æ–‡ä»¶ç³»ç»Ÿçº§çš„ç»†ç²’åº¦ç›‘æ§
"""

import os
import time
import socket
import psutil
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict

logger = logging.getLogger(__name__)


@dataclass
class ProcessMetrics:
    """è¿›ç¨‹æŒ‡æ ‡æ•°æ®ç±»"""
    pid: int
    name: str
    status: str
    cpu_percent: float
    memory_rss: int
    memory_vms: int
    memory_percent: float
    num_threads: int
    num_fds: int
    open_files: int
    connections: int
    io_read_bytes: int
    io_write_bytes: int
    timestamp: str
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class ProcessMonitor:
    """
    è¿›ç¨‹çº§ç›‘æ§å™¨
    
    ç›‘æ§æŒ‡å®šæœåŠ¡çš„è¿›ç¨‹çº§æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ï¼š
    - CPU ä½¿ç”¨ç‡
    - å†…å­˜ä½¿ç”¨è¯¦æƒ…ï¼ˆRSS/VMS/å…±äº«å†…å­˜ï¼‰
    - IO ç»Ÿè®¡ï¼ˆè¯»å†™å­—èŠ‚æ•°ï¼‰
    - çº¿ç¨‹æ•°ã€æ–‡ä»¶æè¿°ç¬¦æ•°
    - ç½‘ç»œè¿æ¥æ•°
    - è¿›ç¨‹çŠ¶æ€
    """
    
    def __init__(self):
        self._cache = {}
        self._cache_ttl = 5  # ç¼“å­˜5ç§’
    
    def collect_process_metrics(self, pid: int) -> Optional[ProcessMetrics]:
        """
        é‡‡é›†æŒ‡å®šè¿›ç¨‹çš„è¯¦ç»†æŒ‡æ ‡
        
        Args:
            pid: è¿›ç¨‹ID
            
        Returns:
            ProcessMetrics å¯¹è±¡ï¼Œå¦‚æœè¿›ç¨‹ä¸å­˜åœ¨è¿”å› None
        """
        try:
            process = psutil.Process(pid)
            
            # è·å–è¿›ç¨‹ä¿¡æ¯
            with process.oneshot():
                cpu_percent = process.cpu_percent(interval=0.1)
                memory_info = process.memory_info()
                io_counters = process.io_counters()
                
                metrics = ProcessMetrics(
                    pid=pid,
                    name=process.name(),
                    status=process.status(),
                    cpu_percent=cpu_percent,
                    memory_rss=memory_info.rss,
                    memory_vms=memory_info.vms,
                    memory_percent=process.memory_percent(),
                    num_threads=process.num_threads(),
                    num_fds=process.num_fds() if hasattr(process, 'num_fds') else 0,
                    open_files=len(process.open_files()),
                    connections=len(process.connections()),
                    io_read_bytes=io_counters.read_bytes,
                    io_write_bytes=io_counters.write_bytes,
                    timestamp=datetime.now().isoformat()
                )
                
                return metrics
                
        except psutil.NoSuchProcess:
            logger.warning(f"è¿›ç¨‹ä¸å­˜åœ¨: PID {pid}")
            return None
        except Exception as e:
            logger.error(f"é‡‡é›†è¿›ç¨‹æŒ‡æ ‡å¤±è´¥ PID {pid}: {e}")
            return None
    
    def find_service_pids(self, service_name: str) -> List[int]:
        """
        æ ¹æ®æœåŠ¡åç§°æŸ¥æ‰¾è¿›ç¨‹ID
        
        Args:
            service_name: æœåŠ¡åç§°ï¼ˆå¦‚ 'yl-monitor', 'ar-backend', 'user-gui'ï¼‰
            
        Returns:
            åŒ¹é…çš„è¿›ç¨‹IDåˆ—è¡¨
        """
        pids = []
        
        try:
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = ' '.join(proc.info['cmdline'] or [])
                    
                    # åŒ¹é…è§„åˆ™
                    if (service_name == 'yl-monitor' and
                            'start_server.py' in cmdline):
                        pids.append(proc.info['pid'])
                    elif (service_name == 'ar-backend' and 
                          'monitor_server.py' in cmdline):
                        pids.append(proc.info['pid'])
                    elif (service_name == 'user-gui' and 
                          'user/main.py' in cmdline):
                        pids.append(proc.info['pid'])
                        
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
                    
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾æœåŠ¡è¿›ç¨‹å¤±è´¥ {service_name}: {e}")
        
        return pids
    
    def monitor_service(self, service_name: str) -> Optional[ProcessMetrics]:
        """
        ç›‘æ§æŒ‡å®šæœåŠ¡ï¼ˆè‡ªåŠ¨æŸ¥æ‰¾è¿›ç¨‹ï¼‰
        
        Args:
            service_name: æœåŠ¡åç§°
            
        Returns:
            è¿›ç¨‹æŒ‡æ ‡ï¼Œå¦‚æœæœåŠ¡æœªè¿è¡Œè¿”å› None
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"service_{service_name}"
        if cache_key in self._cache:
            cached_time, cached_data = self._cache[cache_key]
            if time.time() - cached_time < self._cache_ttl:
                return cached_data
        
        # æŸ¥æ‰¾è¿›ç¨‹
        pids = self.find_service_pids(service_name)
        
        if not pids:
            logger.warning(f"æœåŠ¡æœªè¿è¡Œ: {service_name}")
            return None
        
        # ç›‘æ§ç¬¬ä¸€ä¸ªåŒ¹é…çš„è¿›ç¨‹
        metrics = self.collect_process_metrics(pids[0])
        
        # æ›´æ–°ç¼“å­˜
        if metrics:
            self._cache[cache_key] = (time.time(), metrics)
        
        return metrics
    
    def get_all_services_metrics(self) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰æœåŠ¡çš„è¿›ç¨‹æŒ‡æ ‡
        
        Returns:
            åŒ…å«æ‰€æœ‰æœåŠ¡æŒ‡æ ‡çš„å­—å…¸
        """
        services = ['yl-monitor', 'ar-backend', 'user-gui']
        result = {
            "timestamp": datetime.now().isoformat(),
            "services": {}
        }
        
        for service in services:
            metrics = self.monitor_service(service)
            if metrics:
                result["services"][service] = metrics.to_dict()
            else:
                result["services"][service] = {
                    "status": "not_running",
                    "timestamp": datetime.now().isoformat()
                }
        
        return result


@dataclass
class PortMetrics:
    """ç«¯å£æŒ‡æ ‡æ•°æ®ç±»"""
    host: str
    port: int
    connectable: bool
    connect_time_ms: Optional[float]
    response_time_ms: Optional[float]
    error_code: Optional[int]
    error_message: Optional[str]
    timestamp: str
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class PortMonitor:
    """
    ç«¯å£çº§ç›‘æ§å™¨
    
    ç›‘æ§æœåŠ¡ç«¯å£çš„è¿é€šæ€§å’Œå“åº”æ€§èƒ½ï¼š
    - TCP è¿æ¥æµ‹è¯•
    - è¿æ¥å»ºç«‹æ—¶é—´
    - æœåŠ¡å“åº”æ—¶é—´
    - é”™è¯¯ç åˆ†æ
    """
    
    def __init__(self, timeout: float = 5.0):
        self.timeout = timeout
    
    def check_port(self, host: str, port: int) -> PortMetrics:
        """
        æ£€æŸ¥ç«¯å£è¿é€šæ€§å’Œæ€§èƒ½
        
        Args:
            host: ä¸»æœºåœ°å€
            port: ç«¯å£å·
            
        Returns:
            PortMetrics å¯¹è±¡
        """
        metrics = PortMetrics(
            host=host,
            port=port,
            connectable=False,
            connect_time_ms=None,
            response_time_ms=None,
            error_code=None,
            error_message=None,
            timestamp=datetime.now().isoformat()
        )
        
        # æµ‹è¯• TCP è¿æ¥
        start_time = time.time()
        sock = None
        
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(self.timeout)
            
            result = sock.connect_ex((host, port))
            connect_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            metrics.connect_time_ms = connect_time
            
            if result == 0:
                metrics.connectable = True
                
                # æµ‹è¯• HTTP å“åº”ï¼ˆå¦‚æœæ˜¯ HTTP æœåŠ¡ï¼‰
                try:
                    sock.send(
                        b"GET /health HTTP/1.1\r\nHost:0.0.0.0\r\n\r\n"
                    )
                    response_start = time.time()
                    
                    # ç­‰å¾…å“åº”
                    sock.settimeout(2.0)
                    _ = sock.recv(1024)  # è¯»å–å“åº”ä½†ä¸ä½¿ç”¨
                    response_time = (time.time() - response_start) * 1000
                    
                    metrics.response_time_ms = response_time
                    
                except socket.timeout:
                    metrics.response_time_ms = None
                except Exception as e:
                    logger.debug(f"HTTP å“åº”æµ‹è¯•å¤±è´¥ {host}:{port}: {e}")
            else:
                metrics.error_code = result
                metrics.error_message = (
                    os.strerror(result) if hasattr(os, 'strerror') 
                    else f"Error {result}"
                )
                
        except socket.timeout:
            metrics.error_message = "Connection timeout"
        except Exception as e:
            metrics.error_message = str(e)
            logger.error(f"ç«¯å£æ£€æŸ¥å¤±è´¥ {host}:{port}: {e}")
        finally:
            if sock:
                sock.close()
        
        return metrics
    
    def monitor_service_ports(self) -> Dict[str, Any]:
        """
        ç›‘æ§æ‰€æœ‰æœåŠ¡çš„ç«¯å£
        
        Returns:
            æ‰€æœ‰æœåŠ¡ç«¯å£çš„ç›‘æ§ç»“æœ
        """
        services = {
            'yl-monitor': ('0.0.0.0', 5500),
            'ar-backend': ('0.0.0.0', 5501),
            'user-gui': ('0.0.0.0', 5502)
        }
        
        result = {
            "timestamp": datetime.now().isoformat(),
            "ports": {}
        }
        
        for service, (host, port) in services.items():
            metrics = self.check_port(host, port)
            result["ports"][service] = metrics.to_dict()
        
        return result


@dataclass
class FilesystemMetrics:
    """æ–‡ä»¶ç³»ç»ŸæŒ‡æ ‡æ•°æ®ç±»"""
    path: str
    disk_total: int
    disk_used: int
    disk_free: int
    disk_percent: float
    file_count: int
    dir_count: int
    total_size: int
    timestamp: str
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class FilesystemMonitor:
    """
    æ–‡ä»¶ç³»ç»Ÿç›‘æ§å™¨
    
    ç›‘æ§æ–‡ä»¶ç³»ç»Ÿä½¿ç”¨æƒ…å†µï¼š
    - ç£ç›˜ç©ºé—´ä½¿ç”¨ï¼ˆæ€»/å·²ç”¨/å¯ç”¨ï¼‰
    - æ–‡ä»¶å’Œç›®å½•ç»Ÿè®¡
    - å¤§æ–‡ä»¶è¯†åˆ«
    """
    
    def __init__(self):
        self._cache = {}
        self._cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜ï¼ˆæ–‡ä»¶ç³»ç»Ÿæ‰«æè¾ƒè€—æ—¶ï¼‰
    
    def monitor_disk_usage(self, path: str = '/') -> Dict[str, Any]:
        """
        ç›‘æ§ç£ç›˜ä½¿ç”¨æƒ…å†µ
        
        Args:
            path: è¦ç›‘æ§çš„è·¯å¾„
            
        Returns:
            ç£ç›˜ä½¿ç”¨æŒ‡æ ‡
        """
        try:
            usage = psutil.disk_usage(path)
            
            return {
                "path": path,
                "total": usage.total,
                "used": usage.used,
                "free": usage.free,
                "percent": usage.percent,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ç›‘æ§ç£ç›˜ä½¿ç”¨å¤±è´¥ {path}: {e}")
            return {
                "path": path,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def scan_directory(
        self, path: str, max_depth: int = 2
    ) -> FilesystemMetrics:
        """
        æ‰«æç›®å½•ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
        
        Args:
            path: ç›®å½•è·¯å¾„
            max_depth: æœ€å¤§æ‰«ææ·±åº¦
            
        Returns:
            FilesystemMetrics å¯¹è±¡
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"scan_{path}"
        if cache_key in self._cache:
            cached_time, cached_data = self._cache[cache_key]
            if time.time() - cached_time < self._cache_ttl:
                return cached_data
        
        try:
            path_obj = Path(path)
            
            if not path_obj.exists():
                raise FileNotFoundError(f"è·¯å¾„ä¸å­˜åœ¨: {path}")
            
            # è·å–ç£ç›˜ä½¿ç”¨
            disk_usage = psutil.disk_usage(path)
            
            # ç»Ÿè®¡æ–‡ä»¶
            file_count = 0
            dir_count = 0
            total_size = 0
            
            # é™åˆ¶æ‰«ææ·±åº¦
            for root, dirs, files in os.walk(path):
                # è®¡ç®—å½“å‰æ·±åº¦
                current_depth = (
                    root.count(os.sep) - path.count(os.sep)
                )
                if current_depth >= max_depth:
                    del dirs[:]  # ä¸ç»§ç»­æ·±å…¥
                    continue
                
                dir_count += len(dirs)
                file_count += len(files)
                
                for file in files:
                    try:
                        file_path = os.path.join(root, file)
                        total_size += os.path.getsize(file_path)
                    except (OSError, FileNotFoundError):
                        pass
            
            metrics = FilesystemMetrics(
                path=path,
                disk_total=disk_usage.total,
                disk_used=disk_usage.used,
                disk_free=disk_usage.free,
                disk_percent=disk_usage.percent,
                file_count=file_count,
                dir_count=dir_count,
                total_size=total_size,
                timestamp=datetime.now().isoformat()
            )
            
            # æ›´æ–°ç¼“å­˜
            self._cache[cache_key] = (time.time(), metrics)
            
            return metrics
            
        except Exception as e:
            logger.error(f"æ‰«æç›®å½•å¤±è´¥ {path}: {e}")
            raise
    
    def find_large_files(self, path: str, size_threshold_mb: int = 100) -> List[Dict[str, Any]]:
        """
        æŸ¥æ‰¾å¤§æ–‡ä»¶
        
        Args:
            path: æœç´¢è·¯å¾„
            size_threshold_mb: å¤§å°é˜ˆå€¼ï¼ˆMBï¼‰
            
        Returns:
            å¤§æ–‡ä»¶åˆ—è¡¨
        """
        large_files = []
        threshold_bytes = size_threshold_mb * 1024 * 1024
        
        try:
            for root, dirs, files in os.walk(path):
                for file in files:
                    try:
                        file_path = os.path.join(root, file)
                        size = os.path.getsize(file_path)
                        
                        if size > threshold_bytes:
                            large_files.append({
                                "path": file_path,
                                "size": size,
                                "size_mb": round(size / (1024 * 1024), 2),
                                "modified": datetime.fromtimestamp(
                                    os.path.getmtime(file_path)
                                ).isoformat()
                            })
                            
                    except (OSError, FileNotFoundError):
                        pass
                
                # é™åˆ¶æ‰«æèŒƒå›´
                if len(large_files) >= 50:
                    break
        
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾å¤§æ–‡ä»¶å¤±è´¥ {path}: {e}")
        
        # æŒ‰å¤§å°æ’åº
        large_files.sort(key=lambda x: x['size'], reverse=True)
        return large_files[:20]  # è¿”å›æœ€å¤§çš„20ä¸ª
    
    def monitor_project_directories(self) -> Dict[str, Any]:
        """
        ç›‘æ§é¡¹ç›®å…³é”®ç›®å½•
        
        Returns:
            å„ç›®å½•çš„ç›‘æ§ç»“æœ
        """
        project_root = Path(__file__).parent.parent.parent.parent
        
        directories = {
            'logs': project_root / 'logs',
            'data': project_root / 'data',
            'temp': project_root / 'temp',
            'backups': project_root / 'YL-monitor' / 'backups'
        }
        
        result = {
            "timestamp": datetime.now().isoformat(),
            "directories": {}
        }
        
        for name, path in directories.items():
            try:
                if path.exists():
                    metrics = self.scan_directory(str(path), max_depth=1)
                    result["directories"][name] = metrics.to_dict()
                else:
                    result["directories"][name] = {
                        "path": str(path),
                        "status": "not_exists",
                        "timestamp": datetime.now().isoformat()
                    }
            except Exception as e:
                result["directories"][name] = {
                    "path": str(path),
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }
        
        # æ·»åŠ å¤§æ–‡ä»¶ä¿¡æ¯
        result["large_files"] = self.find_large_files(
            str(project_root),
            size_threshold_mb=50
        )
        
        return result


class InfrastructureCollector:
    """
    åŸºç¡€è®¾æ–½æŒ‡æ ‡é‡‡é›†å™¨
    
    æ•´åˆæ‰€æœ‰åŸºç¡€è®¾æ–½å±‚ç›‘æ§å™¨ï¼Œæä¾›ç»Ÿä¸€æ¥å£
    """
    
    def __init__(self):
        self.process_monitor = ProcessMonitor()
        self.port_monitor = PortMonitor()
        self.filesystem_monitor = FilesystemMonitor()
    
    def collect_all(self) -> Dict[str, Any]:
        """
        é‡‡é›†æ‰€æœ‰åŸºç¡€è®¾æ–½å±‚æŒ‡æ ‡
        
        Returns:
            å®Œæ•´çš„ç›‘æ§æ•°æ®
        """
        return {
            "timestamp": datetime.now().isoformat(),
            "layer": "L1_infrastructure",
            "processes": self.process_monitor.get_all_services_metrics(),
            "ports": self.port_monitor.monitor_service_ports(),
            "filesystem": self.filesystem_monitor.monitor_project_directories()
        }
    
    def get_service_health(self, service_name: str) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šæœåŠ¡çš„å¥åº·çŠ¶æ€
        
        Args:
            service_name: æœåŠ¡åç§°
            
        Returns:
            å¥åº·çŠ¶æ€è¯¦æƒ…
        """
        # è¿›ç¨‹çŠ¶æ€
        process_metrics = self.process_monitor.monitor_service(service_name)
        
        # ç«¯å£çŠ¶æ€
        port_map = {
            'yl-monitor': 5500,
            'ar-backend': 5501,
            'user-gui': 5502
        }
        
        port_metrics = None
        if service_name in port_map:
            port_metrics = self.port_monitor.check_port('0.0.0.0', port_map[service_name])
        
        # ç»¼åˆè¯„ä¼°
        is_healthy = (
            process_metrics is not None and 
            process_metrics.status == 'running' and
            (port_metrics is None or port_metrics.connectable)
        )
        
        return {
            "service": service_name,
            "healthy": is_healthy,
            "process": process_metrics.to_dict() if process_metrics else None,
            "port": port_metrics.to_dict() if port_metrics else None,
            "timestamp": datetime.now().isoformat()
        }


# å…¨å±€é‡‡é›†å™¨å®ä¾‹
infrastructure_collector = InfrastructureCollector()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    print("=" * 60)
    print("åŸºç¡€è®¾æ–½å±‚ç›‘æ§æµ‹è¯•")
    print("=" * 60)
    
    collector = InfrastructureCollector()
    
    # æµ‹è¯•è¿›ç¨‹ç›‘æ§
    print("\n1. è¿›ç¨‹ç›‘æ§:")
    process_metrics = collector.process_monitor.get_all_services_metrics()
    for service, metrics in process_metrics['services'].items():
        if 'status' in metrics and metrics['status'] == 'not_running':
            print(f"  âš ï¸  {service}: æœªè¿è¡Œ")
        else:
            cpu = metrics.get('cpu_percent', 0)
            mem = metrics.get('memory_percent', 0)
            print(f"  âœ… {service}: CPU {cpu:.1f}%, "
              f"å†…å­˜ {mem:.1f}%")
    
    # æµ‹è¯•ç«¯å£ç›‘æ§
    print("\n2. ç«¯å£ç›‘æ§:")
    port_metrics = collector.port_monitor.monitor_service_ports()
    for service, metrics in port_metrics['ports'].items():
        status = "âœ… æ­£å¸¸" if metrics['connectable'] else "âŒ å¼‚å¸¸"
        print(f"  {status} {service} ({metrics['host']}:{metrics['port']}): "
              f"è¿æ¥æ—¶é—´ {metrics.get('connect_time_ms', 'N/A')}ms")
    
    # æµ‹è¯•æ–‡ä»¶ç³»ç»Ÿç›‘æ§
    print("\n3. æ–‡ä»¶ç³»ç»Ÿç›‘æ§:")
    fs_metrics = collector.filesystem_monitor.monitor_project_directories()
    for name, metrics in fs_metrics['directories'].items():
        if 'disk_percent' in metrics:
            print(f"  ğŸ“ {name}: {metrics['disk_percent']:.1f}% ä½¿ç”¨ç‡, "
                  f"{metrics['file_count']} æ–‡ä»¶")
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 60)
